{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0\n",
      "CUDA available: False\n",
      "CUDA version: None\n",
      "Number of GPUs: 0\n",
      "GPU name: No GPU detected\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "## Enforce 4-fold symmetry\n",
    "## Give only 1/4 of waveguide\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shape(shape_matrix):\n",
    "    \"\"\"Plot the generated shape.\"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(6,6))\n",
    "    ax.set_facecolor('#301934')\n",
    "    ax.imshow(shape_matrix, origin='upper')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def load_item(item, action=''):\n",
    "    if action=='':\n",
    "        print(f'Eigenmodes: {item[0]}')\n",
    "        print(f'Weights: {item[1]}')\n",
    "        print(f'Params: {item[2]}')\n",
    "        plot_shape(item[3])\n",
    "    if action == 'shape':\n",
    "        return item[3]\n",
    "    \n",
    "def quarter(matrix):\n",
    "    return matrix[:32, :32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenmodes: tensor([4.9921, 1.5929, 0.5911, 0.0000])\n",
      "Weights: tensor([7.7262e+01, 1.4055e+01, 8.6509e+00, 2.6938e-05])\n",
      "Params: tensor([1.3050, 0.6800, 3.3900, 7.9300])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1098910, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class WaveguideDataset(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        self.h5_file = h5py.File(h5_file, 'r')\n",
    "        weights = self.h5_file['weight_train'][:]  # Shape: (N, 4)\n",
    "        weight_sums = np.sum(weights, axis=1)  # Shape: (N,)\n",
    "        patterns = self.h5_file['pattern_train'][:] # Shape: (N, 64, 64)\n",
    "        mask = weight_sums < 100 # Mask that sorts for just good data \n",
    "\n",
    "        self.eigenmodes = self.h5_file['neff_train'][:]  # Shape: (N, 4)\n",
    "        self.weights = weights[mask]  # Shape: (N, 4)\n",
    "        self.paramss = self.h5_file['params_train'][:][mask]\n",
    "        self.waveguides = np.array([quarter(p) for p in patterns])[mask]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.waveguides)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eigenmode = self.eigenmodes[idx]  # (10, H, W)\n",
    "        weight = self.weights[idx]  # (10,)\n",
    "        params = self.paramss[idx]\n",
    "        waveguide = self.waveguides[idx]  # (H, W)\n",
    "        \n",
    "        \n",
    "        # Normalize (optional)\n",
    "        eigenmode = torch.tensor(eigenmode, dtype=torch.float32)\n",
    "        weight = torch.tensor(weight, dtype=torch.float32)\n",
    "        params = torch.tensor(params, dtype=torch.float32)\n",
    "        waveguide = torch.tensor(waveguide, dtype=torch.float32)\n",
    "\n",
    "        return eigenmode, weight, params, waveguide\n",
    "\n",
    "dataset = WaveguideDataset('train_test_split.h5')\n",
    "load_item(dataset.__getitem__(2))\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "print(dataset.waveguides.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Generator, Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaking with Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, mode_dim=4, weight_dim=4, param_dim=4):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.input_dim = mode_dim + weight_dim + param_dim\n",
    "#         self.init_res = 4  # 4x4 latent feature map to start\n",
    "\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(self.input_dim, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, 128 * self.init_res * self.init_res),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "\n",
    "#         self.upsample = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 4 → 8\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),   # 8 → 16\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),   # 16 → 32\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(16, 1, kernel_size=3, padding=1),                        # Final output: [B, 1, 32, 32]\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, eigenmodes, weights, params):\n",
    "#         # Support numpy or torch input\n",
    "#         if isinstance(eigenmodes, np.ndarray):\n",
    "#             eigenmodes = torch.from_numpy(eigenmodes).float()\n",
    "#         if isinstance(weights, np.ndarray):\n",
    "#             weights = torch.from_numpy(weights).float()\n",
    "#         if isinstance(params, np.ndarray):\n",
    "#             params = torch.from_numpy(params).float()\n",
    "\n",
    "#         device = next(self.parameters()).device\n",
    "#         eigenmodes = eigenmodes.to(device)\n",
    "#         weights = weights.to(device)\n",
    "#         params = params.to(device)\n",
    "\n",
    "#         x = torch.cat((eigenmodes, weights, params), dim=1)  # [B, 12]\n",
    "#         x = self.fc(x)\n",
    "#         x = x.view(-1, 128, self.init_res, self.init_res)    # [B, 128, 4, 4]\n",
    "#         return self.upsample(x)                              # [B, 1, 32, 32]\n",
    "\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self, input_channels=1):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Conv2d(input_channels, 64, kernel_size=3, stride=2, padding=1),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(128 * 8 * 8, 1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remake with Parameters included in Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator output:\n",
      "  waveguide shape: torch.Size([16, 1, 32, 32])\n",
      "  params shape: torch.Size([16, 4])\n",
      "Discriminator output shape: torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, cond_dim=8):\n",
    "        \"\"\"\n",
    "        Generator that maps an input condition (eigenmodes and weights)\n",
    "        to a waveguide image (32x32) and a set of 4 parameters.\n",
    "        \n",
    "        Args:\n",
    "            cond_dim (int): Dimension of the condition input (default=8)\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # First, process the condition through a fully connected network.\n",
    "        # This \"embedding\" is used both to produce the image and the extra parameters.\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(cond_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # For the waveguide branch, map the 512-dimensional feature vector to a feature map:\n",
    "        # We choose 64 channels with a spatial size of 4x4 (64*4*4 = 1024 features).\n",
    "        self.fc_img = nn.Linear(512, 64 * 4 * 4)\n",
    "        \n",
    "        # Then use a series of ConvTranspose2d layers to upscale to 32x32.\n",
    "        self.deconv = nn.Sequential(\n",
    "            # Upsample from 4x4 to 8x8\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            # Upsample from 8x8 to 16x16\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            # Upsample from 16x16 to 32x32; output 1 channel for the binary image.\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()  # Ensures the output is in the range [0,1].\n",
    "        )\n",
    "        \n",
    "        # A branch for predicting the extra four parameters.\n",
    "        self.fc_params = nn.Sequential(\n",
    "            nn.Linear(512, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 4)  # Output: [wavelength, lattice, n_atom, n_lattice]\n",
    "        )\n",
    "    \n",
    "    def forward(self, cond):\n",
    "        \"\"\"\n",
    "        Forward pass of Generator.\n",
    "        \n",
    "        Args:\n",
    "            cond (torch.Tensor): Tensor of shape (batch_size, 8) representing the four eigenmodes and four weights.\n",
    "        \n",
    "        Returns:\n",
    "            waveguide (torch.Tensor): Tensor of shape (batch_size, 1, 32, 32) representing the waveguide image.\n",
    "            params (torch.Tensor): Tensor of shape (batch_size, 4) representing the additional parameters.\n",
    "        \"\"\"\n",
    "        x = self.fc(cond)  # Process condition into a 512-dim feature vector.\n",
    "        \n",
    "        # Generate image: \n",
    "        img_features = self.fc_img(x)\n",
    "        # Reshape to (batch_size, 64, 4, 4)\n",
    "        img_features = img_features.view(-1, 64, 4, 4)\n",
    "        waveguide = self.deconv(img_features)\n",
    "        \n",
    "        # Generate the extra parameters via a separate branch.\n",
    "        params = self.fc_params(x)\n",
    "        \n",
    "        return waveguide, params\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, cond_dim=8):\n",
    "        \"\"\"\n",
    "        Discriminator that judges whether a given tuple (waveguide image, extra parameters, and condition)\n",
    "        comes from the data distribution or from the generator.\n",
    "        \n",
    "        Args:\n",
    "            cond_dim (int): Dimension of the condition input (default=8)\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Convolutional branch to process the waveguide image (assumed to have shape (1, 32, 32)).\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=4, stride=2, padding=1),  # Output: (16, 16, 16)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1), # Output: (32, 8, 8)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1), # Output: (64, 4, 4)\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer to further process flattened image features.\n",
    "        self.fc_image = nn.Linear(64 * 4 * 4, 128)\n",
    "        \n",
    "        # Process the extra parameters (4-D vector).\n",
    "        self.fc_params = nn.Sequential(\n",
    "            nn.Linear(4, 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Process the condition input (8-D vector).\n",
    "        self.fc_cond = nn.Sequential(\n",
    "            nn.Linear(cond_dim, 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Combine all features to produce the final decision.\n",
    "        self.fc_final = nn.Sequential(\n",
    "            nn.Linear(128 + 16 + 16, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()  # Outputs a probability.\n",
    "        )\n",
    "    \n",
    "    def forward(self, waveguide, params, cond):\n",
    "        \"\"\"\n",
    "        Forward pass of Discriminator.\n",
    "        \n",
    "        Args:\n",
    "            waveguide (torch.Tensor): Tensor of shape (batch_size, 1, 32, 32).\n",
    "            params (torch.Tensor): Tensor of shape (batch_size, 4).\n",
    "            cond (torch.Tensor): Tensor of shape (batch_size, 8) with the eigenmodes/weights.\n",
    "        \n",
    "        Returns:\n",
    "            validity (torch.Tensor): Tensor of shape (batch_size, 1) representing the probability of being real.\n",
    "        \"\"\"\n",
    "        batch_size = waveguide.size(0)\n",
    "        x_img = self.cnn(waveguide)\n",
    "        # Flatten image features.\n",
    "        x_img = x_img.view(batch_size, -1)\n",
    "        x_img = self.fc_image(x_img)\n",
    "        \n",
    "        # Embed extra parameters.\n",
    "        x_params = self.fc_params(params)\n",
    "        \n",
    "        # Embed the condition vector.\n",
    "        x_cond = self.fc_cond(cond)\n",
    "        \n",
    "        # Concatenate the three representations.\n",
    "        x = torch.cat([x_img, x_params, x_cond], dim=1)\n",
    "        validity = self.fc_final(x)\n",
    "        \n",
    "        return validity\n",
    "\n",
    "# ---------------------------\n",
    "# Example usage\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Suppose we have a batch size of 16.\n",
    "    batch_size = 16\n",
    "    # Create dummy condition input (4 eigenmodes + 4 weights = 8 features per sample)\n",
    "    cond = torch.randn(batch_size, 8)\n",
    "    \n",
    "    # Initialize the generator and forward propagate.\n",
    "    netG = Generator(cond_dim=8)\n",
    "    fake_waveguide, fake_params = netG(cond)\n",
    "    print(\"Generator output:\")\n",
    "    print(\"  waveguide shape:\", fake_waveguide.shape)  # Should be (16, 1, 32, 32)\n",
    "    print(\"  params shape:\", fake_params.shape)        # Should be (16, 4)\n",
    "    \n",
    "    # Now initialize the discriminator.\n",
    "    netD = Discriminator(cond_dim=8)\n",
    "    # Here, we use the generated outputs along with the same condition.\n",
    "    validity = netD(fake_waveguide, fake_params, cond)\n",
    "    print(\"Discriminator output shape:\", validity.shape)  # Should be (16, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intializing Models and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "lr = 0.0002\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# generator = Generator().to(device)\n",
    "# discriminator = Discriminator().to(device)\n",
    "\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "# optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# epochs = 100\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     start_time = time.perf_counter()\n",
    "#     for eigenmodes, weights, params, real_waveguides in dataloader:\n",
    "#         eigenmodes, weights, params, real_waveguides = eigenmodes.to(device), weights.to(device),  params.to(device), real_waveguides.to(device)\n",
    "\n",
    "#         batch_size = eigenmodes.size(0)\n",
    "#         real_labels = torch.ones(batch_size, 1).to(device)\n",
    "#         fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "#         # Train Discriminator\n",
    "#         optimizer_d.zero_grad()\n",
    "#         # print(real_waveguides.unsqueeze(1).shape)\n",
    "#         real_outputs = discriminator(real_waveguides.unsqueeze(1))\n",
    "#         real_loss = criterion(real_outputs, real_labels)\n",
    "\n",
    "\n",
    "#         # print(eigenmodes.shape[1])\n",
    "#         # print(weights.shape)\n",
    "#         fake_waveguides = generator(eigenmodes, weights, params)\n",
    "#         # print(fake_waveguides.size)\n",
    "#         fake_outputs = discriminator(fake_waveguides.detach())\n",
    "#         fake_loss = criterion(fake_outputs, fake_labels)\n",
    "\n",
    "#         d_loss = real_loss + fake_loss\n",
    "#         d_loss.backward()\n",
    "#         optimizer_d.step()\n",
    "\n",
    "#         # Train Generator\n",
    "#         optimizer_g.zero_grad()\n",
    "#         fake_outputs = discriminator(fake_waveguides)\n",
    "#         g_loss = criterion(fake_outputs, real_labels)  # Want G to fool D\n",
    "#         g_loss.backward()\n",
    "#         optimizer_g.step()\n",
    "\n",
    "#     print(f\"Epoch [{epoch+1}/{epochs}] | D Loss: {d_loss:.4f} | G Loss: {g_loss:.4f}\")\n",
    "#     end_time = time.perf_counter()\n",
    "#     execution_time = end_time - start_time\n",
    "#     print(f\"The Epoch took {execution_time:.4f} seconds to run.\")\n",
    "\n",
    "# print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with new Generator and Descriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39m# Combine discriminator losses and update.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m d_loss \u001b[39m=\u001b[39m real_loss \u001b[39m+\u001b[39m fake_loss\n\u001b[0;32m---> 70\u001b[0m d_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     71\u001b[0m optimizer_d\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     73\u001b[0m \u001b[39m# -------------------------\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m# Train Generator\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39m# -------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    628\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[39m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m         t_outputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    825\u001b[0m     )  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[39mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# Assume Generator and Discriminator have been defined previously and imported.\n",
    "# Generator takes an 8-D condition vector and outputs:\n",
    "#    - waveguide (batch_size, 1, 32, 32)\n",
    "#    - parameters (batch_size, 4)\n",
    "# Discriminator takes:\n",
    "#    - waveguide (batch_size, 1, 32, 32)\n",
    "#    - parameters (batch_size, 4)\n",
    "#    - condition (batch_size, 8)\n",
    "# and outputs a probability.\n",
    "\n",
    "# Set device and hyperparameters.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 0.0002\n",
    "epochs = 100\n",
    "\n",
    "# Instantiate the networks.\n",
    "generator = Generator(cond_dim=8).to(device)\n",
    "discriminator = Discriminator(cond_dim=8).to(device)\n",
    "\n",
    "# Define adversarial loss.\n",
    "criterion_adv = nn.BCELoss()\n",
    "\n",
    "# (Optional) Define a regression loss for the parameters.\n",
    "criterion_param = nn.MSELoss()\n",
    "\n",
    "# Optimizers for both networks.\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Training loop.\n",
    "# Gradient N\n",
    "# Figure out correct enviroment\n",
    "# Plot loss function during training ( to determine convergence )\n",
    "# No gradient explosion/vanishment\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for eigenmodes, weights, params, real_waveguides in dataloader:\n",
    "        # Move data to the appropriate device.\n",
    "        eigenmodes = eigenmodes.to(device)      # shape: (batch_size, 4)\n",
    "        weights = weights.to(device)            # shape: (batch_size, 4)\n",
    "        params = params.to(device)              # shape: (batch_size, 4)\n",
    "        real_waveguides = real_waveguides.to(device)  # shape: (batch_size, 32, 32)\n",
    "        \n",
    "        # Build the condition vector: concatenate eigenmodes and weights.\n",
    "        cond = torch.cat([eigenmodes, weights], dim=1)  # shape: (batch_size, 8)\n",
    "        print(cond.shape)\n",
    "        batch_size = eigenmodes.size(0)\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        # -------------------------\n",
    "        # Train Discriminator\n",
    "        # -------------------------\n",
    "        optimizer_d.zero_grad()\n",
    "        \n",
    "        # Process real data:\n",
    "        # Unsqueeze the channel dimension for the waveguide image.\n",
    "        real_outputs = discriminator(real_waveguides.unsqueeze(1), params, cond)\n",
    "        real_loss = criterion_adv(real_outputs, real_labels)\n",
    "        \n",
    "        # Generate fake data with the generator.\n",
    "        fake_waveguides, fake_params = generator(cond)\n",
    "        fake_outputs = discriminator(fake_waveguides, fake_params, cond)\n",
    "        fake_loss = criterion_adv(fake_outputs, fake_labels)\n",
    "        \n",
    "        # Combine discriminator losses and update.\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        # -------------------------\n",
    "        # Train Generator\n",
    "        # -------------------------\n",
    "        optimizer_g.zero_grad()\n",
    "        \n",
    "        # Re-generate fake data (to ensure proper gradients flow).\n",
    "        fake_waveguides, fake_params = generator(cond)\n",
    "        fake_outputs = discriminator(fake_waveguides, fake_params, cond)\n",
    "        \n",
    "        # Adversarial loss: try to have the discriminator label fakes as real.\n",
    "        g_loss_adv = criterion_adv(fake_outputs, real_labels)\n",
    "        \n",
    "        # (Optional) Parameter loss: force the predicted parameters to match the ground truth.\n",
    "        g_loss_param = criterion_param(fake_params, params)\n",
    "        # A weighting factor can be used to balance the two losses.\n",
    "        lambda_param = 10.0\n",
    "        \n",
    "        g_loss = g_loss_adv + lambda_param * g_loss_param\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
    "    print(f\"Epoch took {epoch_time:.4f} seconds.\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New training with plotting to track model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m d_fake            \u001b[39m=\u001b[39m criterion_adv(fake_out, fake_lbl)\n\u001b[1;32m     57\u001b[0m d_loss \u001b[39m=\u001b[39m d_real \u001b[39m+\u001b[39m d_fake\n\u001b[0;32m---> 58\u001b[0m d_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     59\u001b[0m optimizer_d\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     61\u001b[0m \u001b[39m# — Train Generator —\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    628\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[39m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m         t_outputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    825\u001b[0m     )  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[39mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume Generator, Discriminator, dataloader, (and optional val_dataloader) are defined above.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 2e-4\n",
    "epochs = 100\n",
    "lambda_param = 10.0\n",
    "\n",
    "# Instantiate models and losses\n",
    "generator     = Generator(cond_dim=8).to(device)\n",
    "discriminator = Discriminator(cond_dim=8).to(device)\n",
    "criterion_adv   = nn.BCELoss()\n",
    "criterion_param = nn.MSELoss()\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Prepare lists for logging\n",
    "train_d_losses = []\n",
    "train_g_losses = []\n",
    "val_d_losses   = []\n",
    "val_g_losses   = []\n",
    "\n",
    "# Set up interactive plotting\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    start = time.perf_counter()\n",
    "    d_epoch = []\n",
    "    g_epoch = []\n",
    "\n",
    "    for em, wts, prm, real_wg in dataloader:\n",
    "        bs = em.size(0)\n",
    "        real_lbl = torch.ones(bs,1,device=device)\n",
    "        fake_lbl = torch.zeros(bs,1,device=device)\n",
    "        print('working')\n",
    "        em, wts, prm = em.to(device), wts.to(device), prm.to(device)\n",
    "        real_wg = real_wg.to(device).unsqueeze(1)  # (B,1,32,32)\n",
    "        cond    = torch.cat([em, wts], dim=1)\n",
    "\n",
    "        # — Train Discriminator —\n",
    "        optimizer_d.zero_grad()\n",
    "        real_out = discriminator(real_wg, prm, cond)\n",
    "        d_real   = criterion_adv(real_out, real_lbl)\n",
    "\n",
    "        fake_wg, fake_prm = generator(cond)\n",
    "        fake_out          = discriminator(fake_wg, fake_prm, cond)\n",
    "        d_fake            = criterion_adv(fake_out, fake_lbl)\n",
    "\n",
    "        d_loss = d_real + d_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # — Train Generator —\n",
    "        optimizer_g.zero_grad()\n",
    "        fake_wg2, fake_prm2 = generator(cond)\n",
    "        fake_out2           = discriminator(fake_wg2, fake_prm2, cond)\n",
    "\n",
    "        g_adv   = criterion_adv(fake_out2, real_lbl)\n",
    "        g_param = criterion_param(fake_prm2, prm)\n",
    "        g_loss  = g_adv + lambda_param * g_param\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        d_epoch.append(d_loss.item())\n",
    "        g_epoch.append(g_loss.item())\n",
    "\n",
    "    # Average losses this epoch\n",
    "    avg_d = np.mean(d_epoch)\n",
    "    avg_g = np.mean(g_epoch)\n",
    "    train_d_losses.append(avg_d)\n",
    "    train_g_losses.append(avg_g)\n",
    "\n",
    "    # Optional validation\n",
    "    if 'val_dataloader' in globals():\n",
    "        with torch.no_grad():\n",
    "            d_val = []\n",
    "            g_val = []\n",
    "            for em_v, wts_v, prm_v, wg_v in val_dataloader:\n",
    "                bs_v = em_v.size(0)\n",
    "                real_lbl_v = torch.ones(bs_v,1,device=device)\n",
    "\n",
    "                em_v, wts_v, prm_v = em_v.to(device), wts_v.to(device), prm_v.to(device)\n",
    "                wg_v = wg_v.to(device).unsqueeze(1)\n",
    "                cond_v = torch.cat([em_v, wts_v], dim=1)\n",
    "\n",
    "                # D loss\n",
    "                r_out = discriminator(wg_v, prm_v, cond_v)\n",
    "                f_wg_v, f_prm_v = generator(cond_v)\n",
    "                f_out = discriminator(f_wg_v, f_prm_v, cond_v)\n",
    "                d_val.append((criterion_adv(r_out, real_lbl_v) +\n",
    "                              criterion_adv(f_out, torch.zeros(bs_v,1,device=device))).item())\n",
    "\n",
    "                # G loss\n",
    "                g_val.append((criterion_adv(f_out, real_lbl_v) +\n",
    "                              lambda_param*criterion_param(f_prm_v, prm_v)).item())\n",
    "\n",
    "            val_d_losses.append(np.mean(d_val))\n",
    "            val_g_losses.append(np.mean(g_val))\n",
    "\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"Epoch {epoch:3d}/{epochs} — D: {avg_d:.4f}, G: {avg_g:.4f} — {elapsed:.1f}s\")\n",
    "\n",
    "    # — Update live plot —\n",
    "    ax.clear()\n",
    "    ax.plot(train_d_losses, label='Train D Loss')\n",
    "    ax.plot(train_g_losses, label='Train G Loss')\n",
    "    if val_d_losses:\n",
    "        ax.plot(val_d_losses, '--', label='Val D Loss')\n",
    "        ax.plot(val_g_losses, '--', label='Val G Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('GAN Losses (Live)')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.1)  # small pause to render\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Waveguide Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.1121531e+00 6.1247456e-01 0.0000000e+00 0.0000000e+00 5.3091198e+01\n",
      " 4.6695271e+01 2.7151153e-05 6.7542346e-06]\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_waveguide(generator, eigenmodes_weights):\n",
    "    generator.eval()\n",
    "    eigenmodes_weights = torch.tensor(eigenmodes_weights, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    # weights = torch.tensor(weights, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_waveguide = generator(eigenmodes_weights)\n",
    "    return generated_waveguide\n",
    "    # return generated_waveguide[0, 0]  # Extract single output channel\n",
    "\n",
    "# Example usage\n",
    "eigenmodes_example = dataset[0][0].numpy()  # Use first sample\n",
    "weights_example = dataset[0][1].numpy()\n",
    "cond = np.concatenate((eigenmodes_example, weights_example))\n",
    "print(cond)\n",
    "generated_waveguide, params = generate_waveguide(generator, cond)\n",
    "print(type(generated_waveguide))\n",
    "plt.imshow(generated_waveguide.squeeze(0).squeeze(0), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title(\"Generated 2D Waveguide Pattern\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit ('3.11.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "904b27c75b92146183e9f1345c638188bb604f0e4fe123b9be54acbb552124e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
