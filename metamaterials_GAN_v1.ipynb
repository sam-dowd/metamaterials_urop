{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0\n",
      "CUDA available: False\n",
      "CUDA version: None\n",
      "Number of GPUs: 0\n",
      "GPU name: No GPU detected\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "## Enforce 4-fold symmetry\n",
    "## Give only 1/4 of waveguide\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shape(shape_matrix):\n",
    "    \"\"\"Plot the generated shape.\"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(6,6))\n",
    "    ax.set_facecolor('#301934')\n",
    "    ax.imshow(shape_matrix, origin='upper')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def load_item(item, action=''):\n",
    "    if action=='':\n",
    "        print(f'Eigenmodes: {item[0]}')\n",
    "        print(f'Weights: {item[1]}')\n",
    "        print(f'Params: {item[2]}')\n",
    "        plot_shape(item[3])\n",
    "    if action == 'shape':\n",
    "        return item[3]\n",
    "    \n",
    "def quarter(matrix):\n",
    "    return matrix[:32, :32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenmodes: tensor([4.9921, 1.5929, 0.5911, 0.0000])\n",
      "Weights: tensor([7.7262e+01, 1.4055e+01, 8.6509e+00, 2.6938e-05])\n",
      "Params: tensor([1.3050, 0.6800, 3.3900, 7.9300])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1098910, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class WaveguideDataset(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        self.h5_file = h5py.File(h5_file, 'r')\n",
    "        weights = self.h5_file['weight_train'][:]  # Shape: (N, 4)\n",
    "        weight_sums = np.sum(weights, axis=1)  # Shape: (N,)\n",
    "        patterns = self.h5_file['pattern_train'][:] # Shape: (N, 64, 64)\n",
    "        mask = weight_sums < 100 # Mask that sorts for just good data \n",
    "\n",
    "        self.eigenmodes = self.h5_file['neff_train'][:]  # Shape: (N, 4)\n",
    "        self.weights = weights[mask]  # Shape: (N, 4)\n",
    "        self.paramss = self.h5_file['params_train'][:][mask]\n",
    "        self.waveguides = np.array([quarter(p) for p in patterns])[mask]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.waveguides)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eigenmode = self.eigenmodes[idx]  # (10, H, W)\n",
    "        weight = self.weights[idx]  # (10,)\n",
    "        params = self.paramss[idx]\n",
    "        waveguide = self.waveguides[idx]  # (H, W)\n",
    "        \n",
    "        \n",
    "        # Normalize (optional)\n",
    "        eigenmode = torch.tensor(eigenmode, dtype=torch.float32)\n",
    "        weight = torch.tensor(weight, dtype=torch.float32)\n",
    "        params = torch.tensor(params, dtype=torch.float32)\n",
    "        waveguide = torch.tensor(waveguide, dtype=torch.float32)\n",
    "\n",
    "        return eigenmode, weight, params, waveguide\n",
    "\n",
    "dataset = WaveguideDataset('train_test_split.h5')\n",
    "load_item(dataset.__getitem__(2))\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "print(dataset.waveguides.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Generator, Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaking with Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, mode_dim=4, weight_dim=4, param_dim=4):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.input_dim = mode_dim + weight_dim + param_dim\n",
    "#         self.init_res = 4  # 4x4 latent feature map to start\n",
    "\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(self.input_dim, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, 128 * self.init_res * self.init_res),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "\n",
    "#         self.upsample = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 4 → 8\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),   # 8 → 16\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),   # 16 → 32\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(16, 1, kernel_size=3, padding=1),                        # Final output: [B, 1, 32, 32]\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, eigenmodes, weights, params):\n",
    "#         # Support numpy or torch input\n",
    "#         if isinstance(eigenmodes, np.ndarray):\n",
    "#             eigenmodes = torch.from_numpy(eigenmodes).float()\n",
    "#         if isinstance(weights, np.ndarray):\n",
    "#             weights = torch.from_numpy(weights).float()\n",
    "#         if isinstance(params, np.ndarray):\n",
    "#             params = torch.from_numpy(params).float()\n",
    "\n",
    "#         device = next(self.parameters()).device\n",
    "#         eigenmodes = eigenmodes.to(device)\n",
    "#         weights = weights.to(device)\n",
    "#         params = params.to(device)\n",
    "\n",
    "#         x = torch.cat((eigenmodes, weights, params), dim=1)  # [B, 12]\n",
    "#         x = self.fc(x)\n",
    "#         x = x.view(-1, 128, self.init_res, self.init_res)    # [B, 128, 4, 4]\n",
    "#         return self.upsample(x)                              # [B, 1, 32, 32]\n",
    "\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self, input_channels=1):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Conv2d(input_channels, 64, kernel_size=3, stride=2, padding=1),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(128 * 8 * 8, 1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remake with Parameters included in Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator output:\n",
      "  waveguide shape: torch.Size([16, 1, 32, 32])\n",
      "  params shape: torch.Size([16, 4])\n",
      "Discriminator output shape: torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, cond_dim=8):\n",
    "        \"\"\"\n",
    "        Generator that maps an input condition (eigenmodes and weights)\n",
    "        to a waveguide image (32x32) and a set of 4 parameters.\n",
    "        \n",
    "        Args:\n",
    "            cond_dim (int): Dimension of the condition input (default=8)\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # First, process the condition through a fully connected network.\n",
    "        # This \"embedding\" is used both to produce the image and the extra parameters.\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(cond_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # For the waveguide branch, map the 512-dimensional feature vector to a feature map:\n",
    "        # We choose 64 channels with a spatial size of 4x4 (64*4*4 = 1024 features).\n",
    "        self.fc_img = nn.Linear(512, 64 * 4 * 4)\n",
    "        \n",
    "        # Then use a series of ConvTranspose2d layers to upscale to 32x32.\n",
    "        self.deconv = nn.Sequential(\n",
    "            # Upsample from 4x4 to 8x8\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            # Upsample from 8x8 to 16x16\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            # Upsample from 16x16 to 32x32; output 1 channel for the binary image.\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()  # Ensures the output is in the range [0,1].\n",
    "        )\n",
    "        \n",
    "        # A branch for predicting the extra four parameters.\n",
    "        self.fc_params = nn.Sequential(\n",
    "            nn.Linear(512, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 4)  # Output: [wavelength, lattice, n_atom, n_lattice]\n",
    "        )\n",
    "    \n",
    "    def forward(self, cond):\n",
    "        \"\"\"\n",
    "        Forward pass of Generator.\n",
    "        \n",
    "        Args:\n",
    "            cond (torch.Tensor): Tensor of shape (batch_size, 8) representing the four eigenmodes and four weights.\n",
    "        \n",
    "        Returns:\n",
    "            waveguide (torch.Tensor): Tensor of shape (batch_size, 1, 32, 32) representing the waveguide image.\n",
    "            params (torch.Tensor): Tensor of shape (batch_size, 4) representing the additional parameters.\n",
    "        \"\"\"\n",
    "        x = self.fc(cond)  # Process condition into a 512-dim feature vector.\n",
    "        \n",
    "        # Generate image: \n",
    "        img_features = self.fc_img(x)\n",
    "        # Reshape to (batch_size, 64, 4, 4)\n",
    "        img_features = img_features.view(-1, 64, 4, 4)\n",
    "        waveguide = self.deconv(img_features)\n",
    "        waveguide = (waveguide >= 0.5).float()\n",
    "        # Generate the extra parameters via a separate branch.\n",
    "        params = self.fc_params(x)\n",
    "        \n",
    "        return waveguide, params\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, cond_dim=8):\n",
    "        \"\"\"\n",
    "        Discriminator that judges whether a given tuple (waveguide image, extra parameters, and condition)\n",
    "        comes from the data distribution or from the generator.\n",
    "        \n",
    "        Args:\n",
    "            cond_dim (int): Dimension of the condition input (default=8)\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Convolutional branch to process the waveguide image (assumed to have shape (1, 32, 32)).\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=4, stride=2, padding=1),  # Output: (16, 16, 16)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1), # Output: (32, 8, 8)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1), # Output: (64, 4, 4)\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer to further process flattened image features.\n",
    "        self.fc_image = nn.Linear(64 * 4 * 4, 128)\n",
    "        \n",
    "        # Process the extra parameters (4-D vector).\n",
    "        self.fc_params = nn.Sequential(\n",
    "            nn.Linear(4, 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Process the condition input (8-D vector).\n",
    "        self.fc_cond = nn.Sequential(\n",
    "            nn.Linear(cond_dim, 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Combine all features to produce the final decision.\n",
    "        self.fc_final = nn.Sequential(\n",
    "            nn.Linear(128 + 16 + 16, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()  # Outputs a probability.\n",
    "        )\n",
    "    \n",
    "    def forward(self, waveguide, params, cond):\n",
    "        \"\"\"\n",
    "        Forward pass of Discriminator.\n",
    "        \n",
    "        Args:\n",
    "            waveguide (torch.Tensor): Tensor of shape (batch_size, 1, 32, 32).\n",
    "            params (torch.Tensor): Tensor of shape (batch_size, 4).\n",
    "            cond (torch.Tensor): Tensor of shape (batch_size, 8) with the eigenmodes/weights.\n",
    "        \n",
    "        Returns:\n",
    "            validity (torch.Tensor): Tensor of shape (batch_size, 1) representing the probability of being real.\n",
    "        \"\"\"\n",
    "        batch_size = waveguide.size(0)\n",
    "        x_img = self.cnn(waveguide)\n",
    "        # Flatten image features.\n",
    "        x_img = x_img.view(batch_size, -1)\n",
    "        x_img = self.fc_image(x_img)\n",
    "        \n",
    "        # Embed extra parameters.\n",
    "        x_params = self.fc_params(params)\n",
    "        \n",
    "        # Embed the condition vector.\n",
    "        x_cond = self.fc_cond(cond)\n",
    "        \n",
    "        # Concatenate the three representations.\n",
    "        x = torch.cat([x_img, x_params, x_cond], dim=1)\n",
    "        validity = self.fc_final(x)\n",
    "        \n",
    "        return validity\n",
    "\n",
    "# ---------------------------\n",
    "# Example usage\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Suppose we have a batch size of 16.\n",
    "    batch_size = 16\n",
    "    # Create dummy condition input (4 eigenmodes + 4 weights = 8 features per sample)\n",
    "    cond = torch.randn(batch_size, 8)\n",
    "    \n",
    "    # Initialize the generator and forward propagate.\n",
    "    netG = Generator(cond_dim=8)\n",
    "    fake_waveguide, fake_params = netG(cond)\n",
    "    print(\"Generator output:\")\n",
    "    print(\"  waveguide shape:\", fake_waveguide.shape)  # Should be (16, 1, 32, 32)\n",
    "    print(\"  params shape:\", fake_params.shape)        # Should be (16, 4)\n",
    "    \n",
    "    # Now initialize the discriminator.\n",
    "    netD = Discriminator(cond_dim=8)\n",
    "    # Here, we use the generated outputs along with the same condition.\n",
    "    validity = netD(fake_waveguide, fake_params, cond)\n",
    "    print(\"Discriminator output shape:\", validity.shape)  # Should be (16, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intializing Models and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "lr = 0.0002\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# generator = Generator().to(device)\n",
    "# discriminator = Discriminator().to(device)\n",
    "\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "# optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# epochs = 100\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     start_time = time.perf_counter()\n",
    "#     for eigenmodes, weights, params, real_waveguides in dataloader:\n",
    "#         eigenmodes, weights, params, real_waveguides = eigenmodes.to(device), weights.to(device),  params.to(device), real_waveguides.to(device)\n",
    "\n",
    "#         batch_size = eigenmodes.size(0)\n",
    "#         real_labels = torch.ones(batch_size, 1).to(device)\n",
    "#         fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "#         # Train Discriminator\n",
    "#         optimizer_d.zero_grad()\n",
    "#         # print(real_waveguides.unsqueeze(1).shape)\n",
    "#         real_outputs = discriminator(real_waveguides.unsqueeze(1))\n",
    "#         real_loss = criterion(real_outputs, real_labels)\n",
    "\n",
    "\n",
    "#         # print(eigenmodes.shape[1])\n",
    "#         # print(weights.shape)\n",
    "#         fake_waveguides = generator(eigenmodes, weights, params)\n",
    "#         # print(fake_waveguides.size)\n",
    "#         fake_outputs = discriminator(fake_waveguides.detach())\n",
    "#         fake_loss = criterion(fake_outputs, fake_labels)\n",
    "\n",
    "#         d_loss = real_loss + fake_loss\n",
    "#         d_loss.backward()\n",
    "#         optimizer_d.step()\n",
    "\n",
    "#         # Train Generator\n",
    "#         optimizer_g.zero_grad()\n",
    "#         fake_outputs = discriminator(fake_waveguides)\n",
    "#         g_loss = criterion(fake_outputs, real_labels)  # Want G to fool D\n",
    "#         g_loss.backward()\n",
    "#         optimizer_g.step()\n",
    "\n",
    "#     print(f\"Epoch [{epoch+1}/{epochs}] | D Loss: {d_loss:.4f} | G Loss: {g_loss:.4f}\")\n",
    "#     end_time = time.perf_counter()\n",
    "#     execution_time = end_time - start_time\n",
    "#     print(f\"The Epoch took {execution_time:.4f} seconds to run.\")\n",
    "\n",
    "# print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with new Generator and Descriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 64\u001b[0m\n\u001b[1;32m     60\u001b[0m optimizer_d\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     62\u001b[0m \u001b[39m# Process real data:\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m# Unsqueeze the channel dimension for the waveguide image.\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m real_outputs \u001b[39m=\u001b[39m discriminator(real_waveguides\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m), params, cond)\n\u001b[1;32m     65\u001b[0m real_loss \u001b[39m=\u001b[39m criterion_adv(real_outputs, real_labels)\n\u001b[1;32m     67\u001b[0m \u001b[39m# Generate fake data with the generator.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[6], line 126\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[0;34m(self, waveguide, params, cond)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mForward pass of Discriminator.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m    validity (torch.Tensor): Tensor of shape (batch_size, 1) representing the probability of being real.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m batch_size \u001b[39m=\u001b[39m waveguide\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 126\u001b[0m x_img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn(waveguide)\n\u001b[1;32m    127\u001b[0m \u001b[39m# Flatten image features.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m x_img \u001b[39m=\u001b[39m x_img\u001b[39m.\u001b[39mview(batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[39m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\n\u001b[1;32m    550\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups\n\u001b[1;32m    551\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# Assume Generator and Discriminator have been defined previously and imported.\n",
    "# Generator takes an 8-D condition vector and outputs:\n",
    "#    - waveguide (batch_size, 1, 32, 32)\n",
    "#    - parameters (batch_size, 4)\n",
    "# Discriminator takes:\n",
    "#    - waveguide (batch_size, 1, 32, 32)\n",
    "#    - parameters (batch_size, 4)\n",
    "#    - condition (batch_size, 8)\n",
    "# and outputs a probability.\n",
    "\n",
    "# Set device and hyperparameters.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 0.0002\n",
    "epochs = 100\n",
    "\n",
    "# Instantiate the networks.\n",
    "generator = Generator(cond_dim=8).to(device)\n",
    "discriminator = Discriminator(cond_dim=8).to(device)\n",
    "\n",
    "# Define adversarial loss.\n",
    "criterion_adv = nn.BCELoss()\n",
    "\n",
    "# (Optional) Define a regression loss for the parameters.\n",
    "criterion_param = nn.MSELoss()\n",
    "\n",
    "# Optimizers for both networks.\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Training loop.\n",
    "# Gradient N\n",
    "# Figure out correct enviroment\n",
    "# Plot loss function during training ( to determine convergence )\n",
    "# No gradient explosion/vanishment\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for eigenmodes, weights, params, real_waveguides in dataloader:\n",
    "        # Move data to the appropriate device.\n",
    "        eigenmodes = eigenmodes.to(device)      # shape: (batch_size, 4)\n",
    "        weights = weights.to(device)            # shape: (batch_size, 4)\n",
    "        params = params.to(device)              # shape: (batch_size, 4)\n",
    "        real_waveguides = real_waveguides.to(device)  # shape: (batch_size, 32, 32)\n",
    "        \n",
    "        # Build the condition vector: concatenate eigenmodes and weights.\n",
    "        cond = torch.cat([eigenmodes, weights], dim=1)  # shape: (batch_size, 8)\n",
    "        print(cond.shape)\n",
    "        batch_size = eigenmodes.size(0)\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        # -------------------------\n",
    "        # Train Discriminator\n",
    "        # -------------------------\n",
    "        optimizer_d.zero_grad()\n",
    "        \n",
    "        # Process real data:\n",
    "        # Unsqueeze the channel dimension for the waveguide image.\n",
    "        real_outputs = discriminator(real_waveguides.unsqueeze(1), params, cond)\n",
    "        real_loss = criterion_adv(real_outputs, real_labels)\n",
    "        \n",
    "        # Generate fake data with the generator.\n",
    "        fake_waveguides, fake_params = generator(cond)\n",
    "        fake_outputs = discriminator(fake_waveguides, fake_params, cond)\n",
    "        fake_loss = criterion_adv(fake_outputs, fake_labels)\n",
    "        \n",
    "        # Combine discriminator losses and update.\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        # -------------------------\n",
    "        # Train Generator\n",
    "        # -------------------------\n",
    "        optimizer_g.zero_grad()\n",
    "        \n",
    "        # Re-generate fake data (to ensure proper gradients flow).\n",
    "        fake_waveguides, fake_params = generator(cond)\n",
    "        fake_outputs = discriminator(fake_waveguides, fake_params, cond)\n",
    "        \n",
    "        # Adversarial loss: try to have the discriminator label fakes as real.\n",
    "        g_loss_adv = criterion_adv(fake_outputs, real_labels)\n",
    "        \n",
    "        # (Optional) Parameter loss: force the predicted parameters to match the ground truth.\n",
    "        g_loss_param = criterion_param(fake_params, params)\n",
    "        # A weighting factor can be used to balance the two losses.\n",
    "        lambda_param = 10.0\n",
    "        \n",
    "        g_loss = g_loss_adv + lambda_param * g_loss_param\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
    "    print(f\"Epoch took {epoch_time:.4f} seconds.\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New training with plotting to track model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m d_real   \u001b[39m=\u001b[39m criterion_adv(real_out, real_lbl)\n\u001b[1;32m     53\u001b[0m fake_wg, fake_prm \u001b[39m=\u001b[39m generator(cond)\n\u001b[0;32m---> 54\u001b[0m fake_out          \u001b[39m=\u001b[39m discriminator(fake_wg, fake_prm, cond)\n\u001b[1;32m     55\u001b[0m d_fake            \u001b[39m=\u001b[39m criterion_adv(fake_out, fake_lbl)\n\u001b[1;32m     57\u001b[0m d_loss \u001b[39m=\u001b[39m d_real \u001b[39m+\u001b[39m d_fake\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[6], line 126\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[0;34m(self, waveguide, params, cond)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mForward pass of Discriminator.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m    validity (torch.Tensor): Tensor of shape (batch_size, 1) representing the probability of being real.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m batch_size \u001b[39m=\u001b[39m waveguide\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 126\u001b[0m x_img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn(waveguide)\n\u001b[1;32m    127\u001b[0m \u001b[39m# Flatten image features.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m x_img \u001b[39m=\u001b[39m x_img\u001b[39m.\u001b[39mview(batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/activation.py:828\u001b[0m, in \u001b[0;36mLeakyReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 828\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mleaky_relu(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnegative_slope, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/functional.py:1900\u001b[0m, in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1896\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   1897\u001b[0m         leaky_relu, (\u001b[39minput\u001b[39m,), \u001b[39minput\u001b[39m, negative_slope\u001b[39m=\u001b[39mnegative_slope, inplace\u001b[39m=\u001b[39minplace\n\u001b[1;32m   1898\u001b[0m     )\n\u001b[1;32m   1899\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m-> 1900\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mleaky_relu_(\u001b[39minput\u001b[39;49m, negative_slope)\n\u001b[1;32m   1901\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1902\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mleaky_relu(\u001b[39minput\u001b[39m, negative_slope)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqoAAAGyCAYAAAAs6OYBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAd+0lEQVR4nO3db2zdVf3A8U/b0VsItAzn2m0WJiii/NlgY7X8CcFUm0CGe2CsYLa58EdkElyjsjFYRWCdCGQJFBcmiA/ATQkQ45YiVheD1Cxsa4KyQWDAJrFlU2ln0Za1398DQ/2Vdbhb2u6wvl7JfbDjOfd7rofqm2/vvSvIsiwLAABITOHh3gAAAAxFqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkKS8Q/X3v/99zJ07N6ZOnRoFBQXx5JNP/s81mzZtinPOOSdyuVx84hOfiIcffngYWwUAYDzJO1S7u7tjxowZ0dTUdEjzX3311bj00kvj4osvjra2tvjWt74VV111VTz11FN5bxYAgPGjIMuybNiLCwriiSeeiHnz5h10zo033hgbNmyIP/3pTwNjX/nKV+Ktt96K5ubm4V4aAIAj3ITRvkBra2vU1NQMGqutrY1vfetbB13T09MTPT09A3/u7++Pv//97/GRj3wkCgoKRmurAAAMU5ZlsW/fvpg6dWoUFo7Mx6BGPVTb29ujvLx80Fh5eXl0dXXFv/71rzj66KMPWNPY2Bi33nrraG8NAIARtnv37vjYxz42Is816qE6HMuWLYv6+vqBP3d2dsaJJ54Yu3fvjtLS0sO4MwAAhtLV1RWVlZVx3HHHjdhzjnqoVlRUREdHx6Cxjo6OKC0tHfJuakRELpeLXC53wHhpaalQBQBI2Ei+TXPUv0e1uro6WlpaBo09/fTTUV1dPdqXBgDgQyzvUP3nP/8ZbW1t0dbWFhH/+fqptra22LVrV0T859f2CxYsGJh/7bXXxs6dO+O73/1u7NixI+6///74+c9/HkuWLBmZVwAAwBEp71B97rnn4uyzz46zzz47IiLq6+vj7LPPjhUrVkRExF//+teBaI2I+PjHPx4bNmyIp59+OmbMmBF33313/PjHP47a2toRegkAAByJPtD3qI6Vrq6uKCsri87OTu9RBQBI0Gj02qi/RxUAAIZDqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkKRhhWpTU1NMnz49SkpKoqqqKjZv3vy+81evXh2f+tSn4uijj47KyspYsmRJ/Pvf/x7WhgEAGB/yDtX169dHfX19NDQ0xNatW2PGjBlRW1sbb7755pDzH3300Vi6dGk0NDTE9u3b48EHH4z169fHTTfd9IE3DwDAkSvvUL3nnnvi6quvjkWLFsVnPvOZWLNmTRxzzDHx0EMPDTn/2WefjfPPPz+uuOKKmD59enzhC1+Iyy+//H/ehQUAYHzLK1R7e3tjy5YtUVNT898nKCyMmpqaaG1tHXLNeeedF1u2bBkI0507d8bGjRvjkksuOeh1enp6oqura9ADAIDxZUI+k/fu3Rt9fX1RXl4+aLy8vDx27Ngx5Jorrrgi9u7dGxdccEFkWRb79++Pa6+99n1/9d/Y2Bi33nprPlsDAOAIM+qf+t+0aVOsXLky7r///ti6dWs8/vjjsWHDhrjtttsOumbZsmXR2dk58Ni9e/dobxMAgMTkdUd10qRJUVRUFB0dHYPGOzo6oqKiYsg1t9xyS8yfPz+uuuqqiIg488wzo7u7O6655ppYvnx5FBYe2Mq5XC5yuVw+WwMA4AiT1x3V4uLimDVrVrS0tAyM9ff3R0tLS1RXVw+55u233z4gRouKiiIiIsuyfPcLAMA4kdcd1YiI+vr6WLhwYcyePTvmzJkTq1evju7u7li0aFFERCxYsCCmTZsWjY2NERExd+7cuOeee+Lss8+OqqqqePnll+OWW26JuXPnDgQrAAC8V96hWldXF3v27IkVK1ZEe3t7zJw5M5qbmwc+YLVr165Bd1BvvvnmKCgoiJtvvjneeOON+OhHPxpz586NO+64Y+ReBQAAR5yC7EPw+/eurq4oKyuLzs7OKC0tPdzbAQDgPUaj10b9U/8AADAcQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQNK1Sbmppi+vTpUVJSElVVVbF58+b3nf/WW2/F4sWLY8qUKZHL5eLUU0+NjRs3DmvDAACMDxPyXbB+/fqor6+PNWvWRFVVVaxevTpqa2vjxRdfjMmTJx8wv7e3Nz7/+c/H5MmT47HHHotp06bF66+/Hscff/xI7B8AgCNUQZZlWT4Lqqqq4txzz4377rsvIiL6+/ujsrIyrr/++li6dOkB89esWRM//OEPY8eOHXHUUUcNa5NdXV1RVlYWnZ2dUVpaOqznAABg9IxGr+X1q//e3t7YsmVL1NTU/PcJCgujpqYmWltbh1zzy1/+Mqqrq2Px4sVRXl4eZ5xxRqxcuTL6+voOep2enp7o6uoa9AAAYHzJK1T37t0bfX19UV5ePmi8vLw82tvbh1yzc+fOeOyxx6Kvry82btwYt9xyS9x9991x++23H/Q6jY2NUVZWNvCorKzMZ5sAABwBRv1T//39/TF58uR44IEHYtasWVFXVxfLly+PNWvWHHTNsmXLorOzc+Cxe/fu0d4mAACJyevDVJMmTYqioqLo6OgYNN7R0REVFRVDrpkyZUocddRRUVRUNDD26U9/Otrb26O3tzeKi4sPWJPL5SKXy+WzNQAAjjB53VEtLi6OWbNmRUtLy8BYf39/tLS0RHV19ZBrzj///Hj55Zejv79/YOyll16KKVOmDBmpAAAQMYxf/dfX18fatWvjpz/9aWzfvj2+8Y1vRHd3dyxatCgiIhYsWBDLli0bmP+Nb3wj/v73v8cNN9wQL730UmzYsCFWrlwZixcvHrlXAQDAESfv71Gtq6uLPXv2xIoVK6K9vT1mzpwZzc3NAx+w2rVrVxQW/rd/Kysr46mnnoolS5bEWWedFdOmTYsbbrghbrzxxpF7FQAAHHHy/h7Vw8H3qAIApO2wf48qAACMFaEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShhWqTU1NMX369CgpKYmqqqrYvHnzIa1bt25dFBQUxLx584ZzWQAAxpG8Q3X9+vVRX18fDQ0NsXXr1pgxY0bU1tbGm2+++b7rXnvttfj2t78dF1544bA3CwDA+JF3qN5zzz1x9dVXx6JFi+Izn/lMrFmzJo455ph46KGHDrqmr68vvvrVr8att94aJ5988gfaMAAA40Neodrb2xtbtmyJmpqa/z5BYWHU1NREa2vrQdd9//vfj8mTJ8eVV155SNfp6emJrq6uQQ8AAMaXvEJ179690dfXF+Xl5YPGy8vLo729fcg1zzzzTDz44IOxdu3aQ75OY2NjlJWVDTwqKyvz2SYAAEeAUf3U/759+2L+/Pmxdu3amDRp0iGvW7ZsWXR2dg48du/ePYq7BAAgRRPymTxp0qQoKiqKjo6OQeMdHR1RUVFxwPxXXnklXnvttZg7d+7AWH9//38uPGFCvPjii3HKKaccsC6Xy0Uul8tnawAAHGHyuqNaXFwcs2bNipaWloGx/v7+aGlpierq6gPmn3baafH8889HW1vbwOOyyy6Liy++ONra2vxKHwCAg8rrjmpERH19fSxcuDBmz54dc+bMidWrV0d3d3csWrQoIiIWLFgQ06ZNi8bGxigpKYkzzjhj0Prjjz8+IuKAcQAA+P/yDtW6urrYs2dPrFixItrb22PmzJnR3Nw88AGrXbt2RWGhv/AKAIAPpiDLsuxwb+J/6erqirKysujs7IzS0tLDvR0AAN5jNHrNrU8AAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASNKwQrWpqSmmT58eJSUlUVVVFZs3bz7o3LVr18aFF14YEydOjIkTJ0ZNTc37zgcAgIhhhOr69eujvr4+GhoaYuvWrTFjxoyora2NN998c8j5mzZtissvvzx+97vfRWtra1RWVsYXvvCFeOONNz7w5gEAOHIVZFmW5bOgqqoqzj333LjvvvsiIqK/vz8qKyvj+uuvj6VLl/7P9X19fTFx4sS47777YsGCBYd0za6urigrK4vOzs4oLS3NZ7sAAIyB0ei1vO6o9vb2xpYtW6Kmpua/T1BYGDU1NdHa2npIz/H222/HO++8EyeccMJB5/T09ERXV9egBwAA40teobp3797o6+uL8vLyQePl5eXR3t5+SM9x4403xtSpUwfF7ns1NjZGWVnZwKOysjKfbQIAcAQY00/9r1q1KtatWxdPPPFElJSUHHTesmXLorOzc+Cxe/fuMdwlAAApmJDP5EmTJkVRUVF0dHQMGu/o6IiKior3XXvXXXfFqlWr4je/+U2cddZZ7zs3l8tFLpfLZ2sAABxh8rqjWlxcHLNmzYqWlpaBsf7+/mhpaYnq6uqDrrvzzjvjtttui+bm5pg9e/bwdwsAwLiR1x3ViIj6+vpYuHBhzJ49O+bMmROrV6+O7u7uWLRoUURELFiwIKZNmxaNjY0REfGDH/wgVqxYEY8++mhMnz594L2sxx57bBx77LEj+FIAADiS5B2qdXV1sWfPnlixYkW0t7fHzJkzo7m5eeADVrt27YrCwv/eqP3Rj34Uvb298aUvfWnQ8zQ0NMT3vve9D7Z7AACOWHl/j+rh4HtUAQDSdti/RxUAAMaKUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIEnDCtWmpqaYPn16lJSURFVVVWzevPl95//iF7+I0047LUpKSuLMM8+MjRs3DmuzAACMH3mH6vr166O+vj4aGhpi69atMWPGjKitrY0333xzyPnPPvtsXH755XHllVfGtm3bYt68eTFv3rz405/+9IE3DwDAkasgy7IsnwVVVVVx7rnnxn333RcREf39/VFZWRnXX399LF269ID5dXV10d3dHb/61a8Gxj772c/GzJkzY82aNYd0za6urigrK4vOzs4oLS3NZ7sAAIyB0ei1CflM7u3tjS1btsSyZcsGxgoLC6OmpiZaW1uHXNPa2hr19fWDxmpra+PJJ5886HV6enqip6dn4M+dnZ0R8Z//AgAASM+7nZbnPdD3lVeo7t27N/r6+qK8vHzQeHl5eezYsWPINe3t7UPOb29vP+h1Ghsb49Zbbz1gvLKyMp/tAgAwxv72t79FWVnZiDxXXqE6VpYtWzboLuxbb70VJ510UuzatWvEXjjp6urqisrKyti9e7e3eowDznt8cd7ji/MeXzo7O+PEE0+ME044YcSeM69QnTRpUhQVFUVHR8eg8Y6OjqioqBhyTUVFRV7zIyJyuVzkcrkDxsvKyvyDPo6UlpY673HEeY8vznt8cd7jS2HhyH37aV7PVFxcHLNmzYqWlpaBsf7+/mhpaYnq6uoh11RXVw+aHxHx9NNPH3Q+AABEDONX//X19bFw4cKYPXt2zJkzJ1avXh3d3d2xaNGiiIhYsGBBTJs2LRobGyMi4oYbboiLLroo7r777rj00ktj3bp18dxzz8UDDzwwsq8EAIAjSt6hWldXF3v27IkVK1ZEe3t7zJw5M5qbmwc+MLVr165Bt3zPO++8ePTRR+Pmm2+Om266KT75yU/Gk08+GWecccYhXzOXy0VDQ8OQbwfgyOO8xxfnPb447/HFeY8vo3HeeX+PKgAAjIWRe7crAACMIKEKAECShCoAAEkSqgAAJCmZUG1qaorp06dHSUlJVFVVxebNm993/i9+8Ys47bTToqSkJM4888zYuHHjGO2UkZDPea9duzYuvPDCmDhxYkycODFqamr+5z8fpCXfn+93rVu3LgoKCmLevHmju0FGVL7n/dZbb8XixYtjypQpkcvl4tRTT/W/6R8i+Z736tWr41Of+lQcffTRUVlZGUuWLIl///vfY7Rbhuv3v/99zJ07N6ZOnRoFBQXx5JNP/s81mzZtinPOOSdyuVx84hOfiIcffjj/C2cJWLduXVZcXJw99NBD2Z///Ofs6quvzo4//viso6NjyPl/+MMfsqKiouzOO+/MXnjhhezmm2/OjjrqqOz5558f450zHPme9xVXXJE1NTVl27Zty7Zv35597Wtfy8rKyrK//OUvY7xzhiPf837Xq6++mk2bNi278MILsy9+8Ytjs1k+sHzPu6enJ5s9e3Z2ySWXZM8880z26quvZps2bcra2trGeOcMR77n/cgjj2S5XC575JFHsldffTV76qmnsilTpmRLliwZ452Tr40bN2bLly/PHn/88SwisieeeOJ95+/cuTM75phjsvr6+uyFF17I7r333qyoqChrbm7O67pJhOqcOXOyxYsXD/y5r68vmzp1atbY2Djk/C9/+cvZpZdeOmisqqoq+/rXvz6q+2Rk5Hve77V///7suOOOy37605+O1hYZQcM57/3792fnnXde9uMf/zhbuHChUP0Qyfe8f/SjH2Unn3xy1tvbO1ZbZATle96LFy/OPve5zw0aq6+vz84///xR3Scj61BC9bvf/W52+umnDxqrq6vLamtr87rWYf/Vf29vb2zZsiVqamoGxgoLC6OmpiZaW1uHXNPa2jpofkREbW3tQeeTjuGc93u9/fbb8c4778QJJ5wwWttkhAz3vL///e/H5MmT48orrxyLbTJChnPev/zlL6O6ujoWL14c5eXlccYZZ8TKlSujr69vrLbNMA3nvM8777zYsmXLwNsDdu7cGRs3boxLLrlkTPbM2BmpVsv7b6YaaXv37o2+vr6Bv9nqXeXl5bFjx44h17S3tw85v729fdT2ycgYznm/14033hhTp0494AeA9AznvJ955pl48MEHo62tbQx2yEgaznnv3Lkzfvvb38ZXv/rV2LhxY7z88stx3XXXxTvvvBMNDQ1jsW2GaTjnfcUVV8TevXvjggsuiCzLYv/+/XHttdfGTTfdNBZbZgwdrNW6urriX//6Vxx99NGH9DyH/Y4q5GPVqlWxbt26eOKJJ6KkpORwb4cRtm/fvpg/f36sXbs2Jk2adLi3wxjo7++PyZMnxwMPPBCzZs2Kurq6WL58eaxZs+Zwb41RsGnTpli5cmXcf//9sXXr1nj88cdjw4YNcdtttx3urZGow35HddKkSVFUVBQdHR2Dxjs6OqKiomLINRUVFXnNJx3DOe933XXXXbFq1ar4zW9+E2edddZobpMRku95v/LKK/Haa6/F3LlzB8b6+/sjImLChAnx4osvximnnDK6m2bYhvPzPWXKlDjqqKOiqKhoYOzTn/50tLe3R29vbxQXF4/qnhm+4Zz3LbfcEvPnz4+rrroqIiLOPPPM6O7ujmuuuSaWL18ehYXunx0pDtZqpaWlh3w3NSKBO6rFxcUxa9asaGlpGRjr7++PlpaWqK6uHnJNdXX1oPkREU8//fRB55OO4Zx3RMSdd94Zt912WzQ3N8fs2bPHYquMgHzP+7TTTovnn38+2traBh6XXXZZXHzxxdHW1haVlZVjuX3yNJyf7/PPPz9efvnlgX8hiYh46aWXYsqUKSI1ccM577fffvuAGH33X1L+8xkdjhQj1mr5fc5rdKxbty7L5XLZww8/nL3wwgvZNddckx1//PFZe3t7lmVZNn/+/Gzp0qUD8//whz9kEyZMyO66665s+/btWUNDg6+n+hDJ97xXrVqVFRcXZ4899lj217/+deCxb9++w/USyEO+5/1ePvX/4ZLvee/atSs77rjjsm9+85vZiy++mP3qV7/KJk+enN1+++2H6yWQh3zPu6GhITvuuOOyn/3sZ9nOnTuzX//619kpp5ySffnLXz5cL4FDtG/fvmzbtm3Ztm3bsojI7rnnnmzbtm3Z66+/nmVZli1dujSbP3/+wPx3v57qO9/5TrZ9+/asqanpw/v1VFmWZffee2924oknZsXFxdmcOXOyP/7xjwP/2UUXXZQtXLhw0Pyf//zn2amnnpoVFxdnp59+erZhw4Yx3jEfRD7nfdJJJ2URccCjoaFh7DfOsOT78/3/CdUPn3zP+9lnn82qqqqyXC6XnXzyydkdd9yR7d+/f4x3zXDlc97vvPNO9r3vfS875ZRTspKSkqyysjK77rrrsn/84x9jv3Hy8rvf/W7I/y9+93wXLlyYXXTRRQesmTlzZlZcXJydfPLJ2U9+8pO8r1uQZe61AwCQnsP+HlUAABiKUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACS9H+QH23U13ZuJwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg') # Or 'QtAgg', 'WXAgg'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume Generator, Discriminator, dataloader, (and optional val_dataloader) are defined above.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 2e-4\n",
    "epochs = 100\n",
    "lambda_param = 10.0\n",
    "\n",
    "# Instantiate models and losses\n",
    "generator     = Generator(cond_dim=8).to(device)\n",
    "discriminator = Discriminator(cond_dim=8).to(device)\n",
    "criterion_adv   = nn.BCELoss()\n",
    "criterion_param = nn.MSELoss()\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Prepare lists for logging\n",
    "train_d_losses = []\n",
    "train_g_losses = []\n",
    "# val_d_losses   = []\n",
    "# val_g_losses   = []\n",
    "\n",
    "# Set up interactive plotting\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    start = time.perf_counter()\n",
    "    d_epoch = []\n",
    "    g_epoch = []\n",
    "\n",
    "    for em, wts, prm, real_wg in dataloader:\n",
    "        bs = em.size(0)\n",
    "        real_lbl = torch.ones(bs,1,device=device)\n",
    "        fake_lbl = torch.zeros(bs,1,device=device)\n",
    "        print('working')\n",
    "        em, wts, prm = em.to(device), wts.to(device), prm.to(device)\n",
    "        real_wg = real_wg.to(device).unsqueeze(1)  # (B,1,32,32)\n",
    "        cond    = torch.cat([em, wts], dim=1)\n",
    "\n",
    "        # — Train Discriminator —\n",
    "        optimizer_d.zero_grad()\n",
    "        real_out = discriminator(real_wg, prm, cond)\n",
    "        d_real   = criterion_adv(real_out, real_lbl)\n",
    "\n",
    "        fake_wg, fake_prm = generator(cond)\n",
    "        fake_out          = discriminator(fake_wg, fake_prm, cond)\n",
    "        d_fake            = criterion_adv(fake_out, fake_lbl)\n",
    "\n",
    "        d_loss = d_real + d_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # — Train Generator —\n",
    "        optimizer_g.zero_grad()\n",
    "        fake_wg2, fake_prm2 = generator(cond)\n",
    "        fake_out2           = discriminator(fake_wg2, fake_prm2, cond)\n",
    "\n",
    "        g_adv   = criterion_adv(fake_out2, real_lbl)\n",
    "        g_param = criterion_param(fake_prm2, prm)\n",
    "        g_loss  = g_adv + lambda_param * g_param\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        d_epoch.append(d_loss.item())\n",
    "        g_epoch.append(g_loss.item())\n",
    "\n",
    "    # Average losses this epoch\n",
    "    avg_d = np.mean(d_epoch)\n",
    "    avg_g = np.mean(g_epoch)\n",
    "    train_d_losses.append(avg_d)\n",
    "    train_g_losses.append(avg_g)\n",
    "\n",
    "\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"Epoch {epoch:3d}/{epochs} — D: {avg_d:.4f}, G: {avg_g:.4f} — {elapsed:.1f}s\")\n",
    "\n",
    "    # — Update live plot —\n",
    "    ax.clear()\n",
    "    ax.plot(train_d_losses, label='Train D Loss')\n",
    "    ax.plot(train_g_losses, label='Train G Loss')\n",
    "\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('GAN Losses (Live)')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.1)  # small pause to render\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Waveguide Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.1121531e+00 6.1247456e-01 0.0000000e+00 0.0000000e+00 5.3091198e+01\n",
      " 4.6695271e+01 2.7151153e-05 6.7542346e-06]\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_waveguide(generator, eigenmodes_weights):\n",
    "    generator.eval()\n",
    "    eigenmodes_weights = torch.tensor(eigenmodes_weights, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    # weights = torch.tensor(weights, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_waveguide = generator(eigenmodes_weights)\n",
    "    return generated_waveguide\n",
    "    # return generated_waveguide[0, 0]  # Extract single output channel\n",
    "\n",
    "# Example usage\n",
    "eigenmodes_example = dataset[0][0].numpy()  # Use first sample\n",
    "weights_example = dataset[0][1].numpy()\n",
    "cond = np.concatenate((eigenmodes_example, weights_example))\n",
    "print(cond)\n",
    "generated_waveguide, params = generate_waveguide(generator, cond)\n",
    "print(type(generated_waveguide))\n",
    "plt.imshow(generated_waveguide.squeeze(0).squeeze(0), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title(\"Generated 2D Waveguide Pattern\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m ax\u001b[39m.\u001b[39mlegend(loc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mupper right\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[0;32m---> 20\u001b[0m plt\u001b[39m.\u001b[39;49mpause(\u001b[39m0.1\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/matplotlib/pyplot.py:756\u001b[0m, in \u001b[0;36mpause\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    754\u001b[0m         canvas\u001b[39m.\u001b[39mdraw_idle()\n\u001b[1;32m    755\u001b[0m     show(block\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 756\u001b[0m     canvas\u001b[39m.\u001b[39;49mstart_event_loop(interval)\n\u001b[1;32m    757\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    758\u001b[0m     time\u001b[39m.\u001b[39msleep(interval)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/matplotlib/backends/_backend_tk.py:423\u001b[0m, in \u001b[0;36mFigureCanvasTk.start_event_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_loop_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tkcanvas\u001b[39m.\u001b[39mafter_idle(\n\u001b[1;32m    422\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_event_loop)\n\u001b[0;32m--> 423\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tkcanvas\u001b[39m.\u001b[39;49mmainloop()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/tkinter/__init__.py:1485\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmainloop\u001b[39m(\u001b[39mself\u001b[39m, n\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m   1484\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1485\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtk\u001b[39m.\u001b[39mmainloop(n)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/tkinter/__init__.py:1943\u001b[0m, in \u001b[0;36mCallWrapper.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1940\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubst \u001b[39m=\u001b[39m subst\n\u001b[1;32m   1941\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidget \u001b[39m=\u001b[39m widget\n\u001b[0;32m-> 1943\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[1;32m   1944\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Apply first function SUBST to arguments, than FUNC.\"\"\"\u001b[39;00m\n\u001b[1;32m   1945\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg') # Or 'QtAgg', 'WXAgg'\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "bruh = []\n",
    "bruh2 = []\n",
    "for i in range(0,100):\n",
    "    bruh.append(i)\n",
    "    bruh2.append(i)\n",
    "    ax.clear()\n",
    "    ax.plot(bruh, label='Train D Loss')\n",
    "    ax.plot(bruh2, label='Train G Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('GAN Losses (Live)')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit ('3.11.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "904b27c75b92146183e9f1345c638188bb604f0e4fe123b9be54acbb552124e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
