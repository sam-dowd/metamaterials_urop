{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0\n",
      "CUDA available: False\n",
      "CUDA version: None\n",
      "Number of GPUs: 0\n",
      "GPU name: No GPU detected\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "# useful v1 functions\n",
    "import import_ipynb \n",
    "from metamaterials_GAN_v1 import plot_shape, load_item, quarter, dataset, dataloader\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WGAN implementation attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Generator, same as in v1\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, cond_dim=8):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(cond_dim, 128), nn.ReLU(True),\n",
    "            nn.Linear(128, 512),       nn.ReLU(True),\n",
    "        )\n",
    "        self.fc_img = nn.Linear(512, 64 * 4 * 4)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 1,  4, 2, 1), nn.Sigmoid(),\n",
    "        )\n",
    "        self.fc_params = nn.Sequential(\n",
    "            nn.Linear(512, 32), nn.ReLU(True),\n",
    "            nn.Linear(32, 4),\n",
    "        )\n",
    "    \n",
    "    def forward(self, cond):\n",
    "        x = self.fc(cond)\n",
    "        img_feats = self.fc_img(x).view(-1, 64, 4, 4)\n",
    "        waveguide = self.deconv(img_feats)\n",
    "        params    = self.fc_params(x)\n",
    "        return waveguide, params\n",
    "\n",
    "# Critic (formerly Discriminator)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, cond_dim=8):\n",
    "        super(Critic, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 4, 2, 1), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(16,32, 4, 2, 1), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(32,64, 4, 2, 1), nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "        self.fc_image = nn.Linear(64*4*4, 128)\n",
    "        self.fc_params = nn.Sequential(\n",
    "            nn.Linear(4, 16), nn.LeakyReLU(0.2, True)\n",
    "        )\n",
    "        self.fc_cond = nn.Sequential(\n",
    "            nn.Linear(cond_dim, 16), nn.LeakyReLU(0.2, True)\n",
    "        )\n",
    "        # No final Sigmoid—raw score output\n",
    "        self.fc_final = nn.Sequential(\n",
    "            nn.Linear(128+16+16, 64),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, waveguide, params, cond):\n",
    "        bsz = waveguide.size(0)\n",
    "        x_img = self.cnn(waveguide).view(bsz, -1)\n",
    "        x_img = self.fc_image(x_img)\n",
    "        x_p   = self.fc_params(params)\n",
    "        x_c   = self.fc_cond(cond)\n",
    "        x     = torch.cat([x_img, x_p, x_c], dim=1)\n",
    "        return self.fc_final(x)  # “critic score”\n",
    "\n",
    "# WGAN Training Loop\n",
    "\n",
    "def train_wgan(\n",
    "    netG, netC, dataloader, \n",
    "    epochs=100, \n",
    "    n_critic=5, \n",
    "    clip_value=0.01, \n",
    "    lr=5e-5,\n",
    "    device=torch.device(\"cpu\")\n",
    "):\n",
    "    # Optimizers\n",
    "    optC = optim.RMSprop(netC.parameters(), lr=lr)\n",
    "    optG = optim.RMSprop(netG.parameters(), lr=lr)\n",
    "    \n",
    "    netG.to(device)\n",
    "    netC.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (real_wave, real_params, cond) in enumerate(dataloader):\n",
    "            real_wave   = real_wave.to(device)\n",
    "            real_params = real_params.to(device)\n",
    "            cond        = cond.to(device)\n",
    "            \n",
    "            # Train Critic\n",
    "            for _ in range(n_critic):\n",
    "                netC.zero_grad()\n",
    "                # Real score\n",
    "                real_score = netC(real_wave, real_params, cond).mean()\n",
    "                # Fake score\n",
    "                fake_wave, fake_params = netG(cond)\n",
    "                fake_score = netC(fake_wave.detach(), fake_params.detach(), cond).mean()\n",
    "                \n",
    "                lossC = fake_score - real_score\n",
    "                lossC.backward()\n",
    "                optC.step()\n",
    "                \n",
    "                # Weight clipping\n",
    "                for p in netC.parameters():\n",
    "                    p.data.clamp_(-clip_value, clip_value)\n",
    "            \n",
    "            # Train Generator\n",
    "            netG.zero_grad()\n",
    "            gen_wave, gen_params = netG(cond)\n",
    "            gen_score = netC(gen_wave, gen_params, cond).mean()\n",
    "            lossG = -gen_score\n",
    "            lossG.backward()\n",
    "            optG.step()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]  Loss_C: {lossC.item():.4f}  Loss_G: {lossG.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialzing Models and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generator = Generator().to(device)\n",
    "critic    = Critic().to(device)\n",
    "\n",
    "lr = 5e-5\n",
    "n_critic = 5 # how many critic steps per generator step\n",
    "clip_value = 0.01 # weight‑clipping range\n",
    "\n",
    "optimizer_g = optim.RMSprop(generator.parameters(), lr=lr)\n",
    "optimizer_c = optim.RMSprop(critic.parameters(),    lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import matplotlib\n",
    "    matplotlib.use('TkAgg')  # Or 'QtAgg', 'WXAgg'\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # — Device and hyperparameters —\n",
    "\n",
    "    epochs       = 100\n",
    "    lambda_param = 10.0\n",
    "\n",
    "    # — Models —\n",
    "    generator = Generator(cond_dim=8).to(device)\n",
    "    critic    = Critic(cond_dim=8).to(device)\n",
    "\n",
    "    # — Loss for parameter regression —\n",
    "    criterion_param = nn.MSELoss()\n",
    "\n",
    "    # — Optimizers (original WGAN uses RMSprop) —\n",
    "    optimizer_g = optim.RMSprop(generator.parameters(), lr=lr)\n",
    "    optimizer_c = optim.RMSprop(critic.parameters(),    lr=lr)\n",
    "\n",
    "    # — Logging lists —\n",
    "    train_c_losses = []\n",
    "    train_g_losses = []\n",
    "\n",
    "    # — Interactive plot setup —\n",
    "    plt.ion()\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        start = time.perf_counter()\n",
    "        c_epoch = []\n",
    "        g_epoch = []\n",
    "\n",
    "        for em, wts, prm, real_wg in dataloader:\n",
    "            # Move data to device\n",
    "            em, wts, prm = em.to(device), wts.to(device), prm.to(device)\n",
    "            real_wg      = real_wg.to(device).unsqueeze(1)   # (B,1,32,32)\n",
    "            cond         = torch.cat([em, wts], dim=1)\n",
    "\n",
    "            # — Train Critic n_critic times —\n",
    "            for _ in range(n_critic):\n",
    "                critic.zero_grad()\n",
    "                # Real score\n",
    "                real_score = critic(real_wg, prm, cond).mean()\n",
    "                # Fake score (detach so generator isn't updated here)\n",
    "                fake_wg, fake_prm = generator(cond)\n",
    "                fake_score = critic(fake_wg.detach(), fake_prm.detach(), cond).mean()\n",
    "                # Wasserstein critic loss\n",
    "                c_loss = fake_score - real_score\n",
    "                c_loss.backward()\n",
    "                optimizer_c.step()\n",
    "\n",
    "                # Weight clipping\n",
    "                for p in critic.parameters():\n",
    "                    p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "            # — Train Generator —\n",
    "            generator.zero_grad()\n",
    "            fake_wg2, fake_prm2 = generator(cond)\n",
    "            # Adversarial term (want critic to rate fake samples high)\n",
    "            g_adv = -critic(fake_wg2, fake_prm2, cond).mean()\n",
    "            # Regression term on the parameters\n",
    "            g_param = criterion_param(fake_prm2, prm)\n",
    "            # Combined generator loss\n",
    "            g_loss = g_adv + lambda_param * g_param\n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "            c_epoch.append(c_loss.item())\n",
    "            g_epoch.append(g_loss.item())\n",
    "\n",
    "        # — Epoch summaries —\n",
    "        avg_c = np.mean(c_epoch)\n",
    "        avg_g = np.mean(g_epoch)\n",
    "        train_c_losses.append(avg_c)\n",
    "        train_g_losses.append(avg_g)\n",
    "        elapsed = time.perf_counter() - start\n",
    "\n",
    "        print(f\"Epoch {epoch:3d}/{epochs} — Critic: {avg_c:.4f}, Generator: {avg_g:.4f} — {elapsed:.1f}s\")\n",
    "\n",
    "        # — Update live plot —\n",
    "        ax.clear()\n",
    "        ax.plot(train_c_losses, label='Train Critic Loss')\n",
    "        ax.plot(train_g_losses, label='Train Generator Loss')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_title('WGAN Losses (Live)')\n",
    "        ax.legend(loc='upper right')\n",
    "        plt.tight_layout()\n",
    "        plt.pause(0.1)\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "\n",
    "    # — Save the generator weights —\n",
    "    save_dir  = \"./models\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, \"generator_wgan.pth\")\n",
    "    torch.save(generator.state_dict(), save_path)\n",
    "    print(f\"Generator state_dict saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the final Generated Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_waveguide(generator, eigenmodes_weights):\n",
    "    \"\"\"\n",
    "    Given a trained WGAN generator and a flat vector of 8 cond features\n",
    "    (4 eigenmodes + 4 weights), returns the generated waveguide and params.\n",
    "    \"\"\"\n",
    "    device = next(generator.parameters()).device\n",
    "    x = (\n",
    "        torch.tensor(eigenmodes_weights, dtype=torch.float32)\n",
    "             .unsqueeze(0)\n",
    "             .to(device)\n",
    "    )\n",
    "\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        waveguide, params = generator(x)\n",
    "    return waveguide, params\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    gen = Generator(cond_dim=8).to(device)\n",
    "    gen.load_state_dict(torch.load(save_path, map_location=device))\n",
    "    \n",
    "    test_vals = load_item(dataset[1], train=False)\n",
    "    cond = np.concatenate((test_vals[\"Eigenmodes\"], test_vals[\"Weights\"]))\n",
    "\n",
    "    gen_waveguide, gen_params = generate_waveguide(gen, cond)\n",
    "    gen_waveguide = (gen_waveguide >= 0.5).float()\n",
    "    wg = gen_waveguide.squeeze().cpu().numpy()\n",
    "\n",
    "    ## Eye test evaluate \n",
    "    plot_shape(wg)\n",
    "    print(f\"Conditions:       {cond}\")\n",
    "    print(f\"Real Parameters:   {test_vals['Params']}\")\n",
    "    print(f\"Generated Params:  {gen_params.squeeze().cpu().numpy()}\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit ('3.11.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "904b27c75b92146183e9f1345c638188bb604f0e4fe123b9be54acbb552124e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
