{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4th Version of Metamaterials GAN\n",
    "Beginning by following MNIST 'template', then adding complexity as problem dictates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.7.0+cu126\n",
      "CUDA available: True\n",
      "CUDA version: 12.6\n",
      "Number of GPUs: 1\n",
      "GPU name: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "# useful v1 functions\n",
    "import import_ipynb \n",
    "import importlib\n",
    "import metamaterials_GAN_v1\n",
    "importlib.reload(metamaterials_GAN_v1)\n",
    "\n",
    "from metamaterials_GAN_v1 import plot_shape, load_item, quarter, dataset, dataloader\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator for conditional GAN\n",
    "    Inputs:\n",
    "        - Waveguide, size: (batch_size, 1, 32, 32)\n",
    "        - Parameters, size (batchsize, 4)\n",
    "        - Modes (condition), size (batchsize, 4)\n",
    "    Outputs:\n",
    "        - 0-1, if image is real or generated, size (batchsize)\n",
    "    Questions:\n",
    "        - Should I be using dropout in image_fc, or at all in my Discriminator??\n",
    "        - Am I correct in using conv2d and splitting the problem into\n",
    "          image convolution and parameter process and then combining?\n",
    "        - \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Process for waveguide\n",
    "        # Note on conv, output_size = 1 + [(input_size + 2*padding-kernel_size)/stride]\n",
    "        self.image_conv = nn.Sequential(\n",
    "            # Input is an image of shape (1,32,32), meaning greyscale and 32x32 pixels\n",
    "            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1), # (batchsize, 64, 16, 16) -> 65 channels, each of size 16 x 16\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), # (batchsize, 128, 8, 8)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), # (batchsize, 256, 4, 4)\n",
    "            nn.Flatten() #  (batchsize, 256 x 4 x 4 = 4096) for linear output\n",
    "        )\n",
    "\n",
    "        # Process for parameters\n",
    "        self.param_fc = nn.Sequential(\n",
    "            # Need to take (batchsize, 4) and make (batchsize, 256) for concatenation,\n",
    "            # add hidden layer so that we can infer information about parameters as well.\n",
    "            nn.Linear(4,128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 256)\n",
    "        )\n",
    "        # Process for modes\n",
    "        self.cond_fc = nn.Sequential(\n",
    "            # Rescales (batchsize, 4->256), maps to same feature space as image and params\n",
    "            nn.Linear(8, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "        # Full combined model for all processes\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(4096 + 256 + 256, 512), # image + params + cond\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, params, cond):\n",
    "        img_feat = self.image_conv(img)\n",
    "        param_feat = self.param_fc(params)\n",
    "        cond_feat = self.cond_fc(cond)\n",
    "\n",
    "        x = torch.cat([img_feat, param_feat, cond_feat], dim=1)\n",
    "        final = self.model(x)\n",
    "\n",
    "        return final.squeeze() # returns (batchsize), where each number is 0 -> 1 based on how likely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator for conditional GAN\n",
    "    Inputs:\n",
    "        - Modes (condition), size (batchsize, 4)\n",
    "    Outputs:\n",
    "        - Waveguide, size (batchsize, 32, 32)\n",
    "        - Params, size (batchsize, 4)\n",
    "    Questions:\n",
    "        - Should we still be using latent vector like in MNIST, as we want \n",
    "          consistent results i.e. for a set of modes, we want as close \n",
    "          to the same waveguide as possible each time? \n",
    "        - Should I be feeding my generated waveguide shape into my params\n",
    "          process as well (and maybe in discrim too)? Also, does my params\n",
    "          process need more layers?\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            # Need to transform cond vector into higher dimension\n",
    "            # so that we can reshape it for deconv (batchsize, 8 -> 4096)\n",
    "            nn.Linear(8, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(inplace=True) \n",
    "        )\n",
    "        # Output = (input_size-1)*stride-2*padding+kernel_size\n",
    "        self.deconv = nn.Sequential(\n",
    "            # We start with 256 4x4 pieces generated from our cond input\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # 4x4 ->  8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # 8x8 -> 16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1), # 16x16 -> 32x32, greyscale so only 1 output channel\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # Takes in cond and outputs parameters\n",
    "        \n",
    "        self.param_proc = nn.Sequential(\n",
    "            nn.Linear(4096, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 4) # outputs (batchsize, 4)\n",
    "        )\n",
    "    \n",
    "    def forward(self, cond):\n",
    "        x = self.fc(cond) # (batchsize, 8 -> 4096)\n",
    "        cond_feat = x.view(x.size(0), 256, 4, 4) #(batchsize, 4096) -> (batchsize, 256, 4, 4)\n",
    "        image = self.deconv(cond_feat)\n",
    "        params = self.param_proc(x)\n",
    "\n",
    "        return image, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train_step(batch, discriminator, generator, g_optimizer, g_criterion, d_criterion, device, adv_w=1, re_w=1):\n",
    "    generator.train()\n",
    "    g_optimizer.zero_grad()\n",
    "    # will almost certainly have to change but same logic flow\n",
    "    eigenmodes, weights, real_params, real_waveguides = [b.to(device) for b in batch]\n",
    "    cond = torch.cat([eigenmodes, weights], dim=-1)\n",
    "\n",
    "    fake_waveguides, fake_params = generator(cond)\n",
    "    \n",
    "    validity = discriminator(fake_waveguides, fake_params, cond)\n",
    "    adv_loss = d_criterion(validity, Variable(torch.ones_like(validity))) # how it fairs against discriminator\n",
    "\n",
    "    # These are how it fairs against real data, included because only one real result, unsure if to keep? \n",
    "    image_loss = g_criterion(fake_waveguides, real_waveguides)\n",
    "    params_loss = g_criterion(fake_params, real_params)\n",
    "\n",
    "    # can adjust weights to make it fully adversarial \n",
    "    g_loss = adv_loss * adv_w + (image_loss + params_loss) * re_w\n",
    "\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    return g_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_train_step(batch, discriminator, generator, d_optimizer, d_criterion, device):\n",
    "    discriminator.train()\n",
    "    d_optimizer.zero_grad()\n",
    "\n",
    "    eigenmodes, weights, real_params, real_waveguides = [b.to(device) for b in batch]\n",
    "    cond = torch.cat([eigenmodes, weights], dim=-1)\n",
    "\n",
    "    real_validity = discriminator(real_waveguides, real_params, cond)\n",
    "    real_loss = d_criterion(real_validity, Variable(torch.ones_like(real_validity)))\n",
    "\n",
    "    fake_waveguides, fake_params = generator(cond)\n",
    "    fake_validity = discriminator(fake_waveguides, fake_params, cond)\n",
    "    fake_loss = d_criterion(fake_validity, Variable(torch.zeros_like(real_validity)))\n",
    "\n",
    "    d_loss = real_loss + fake_loss\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    return d_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to figure out differences between my dataset structure and MNIST dataset structure\n",
    "\n",
    "Need to implement training loop, remember that output must be binarized before being fed to the discriminator!\n",
    "\n",
    "For binarization, will that not significantly increase the loss of my model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m#for _ in range(n_critic):\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m d_loss = \u001b[43mdiscriminator_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m g_loss = generator_train_step(batch, d, g, g_optimizer, g_criterion, d_criterion, device)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# writer.add_scalars('scalars', {'g_loss': g_loss, 'd_loss': (d_loss / n_critic)}, step)  \u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mdiscriminator_train_step\u001b[39m\u001b[34m(batch, discriminator, generator, d_optimizer, d_criterion, device)\u001b[39m\n\u001b[32m      3\u001b[39m d_optimizer.zero_grad()\n\u001b[32m      5\u001b[39m eigenmodes, weights, real_params, real_waveguides = [b.to(device) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m cond = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43meigenmodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m real_validity = discriminator(real_waveguides, real_params, cond)\n\u001b[32m      9\u001b[39m real_loss = d_criterion(real_validity, Variable(torch.ones_like(real_validity)))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # set up device\n",
    "\n",
    "from datetime import datetime\n",
    "d = Discriminator().to(device)\n",
    "g = Generator().to(device) \n",
    "d_optimizer = torch.optim.Adam(d.parameters(), lr=1e-4)\n",
    "g_optimizer = torch.optim.Adam(g.parameters(), lr=1e-4)\n",
    "d_criterion = nn.BCELoss() # outputs [0,1]\n",
    "g_criterion = nn.MSELoss() # outputs [-1,1]\n",
    "\n",
    "run_name = f\"WGAN-lr1e4-bs32-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"runs/gan_experiments_test_/{run_name}\")\n",
    "num_epochs = 50\n",
    "# n_critic = 5\n",
    "display_step = 1000\n",
    "save_path = 'models/generator_v4_test.pth' \n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    print('Starting epoch {}...'.format(epoch), end=' ')\n",
    "    i = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        step = epoch * len(dataloader) + i + 1\n",
    "        i += 1\n",
    "\n",
    "        #for _ in range(n_critic):\n",
    "        d_loss = discriminator_train_step(batch, d,g, d_optimizer, d_criterion, device)\n",
    "        \n",
    "        g_loss = generator_train_step(batch, d, g, g_optimizer, g_criterion, d_criterion, device)\n",
    "        # writer.add_scalars('scalars', {'g_loss': g_loss, 'd_loss': (d_loss / n_critic)}, step)  \n",
    "        writer.add_scalars('scalars', {'g_loss': g_loss, 'd_loss': (d_loss)}, step)\n",
    "        # print(step)\n",
    "        if step % display_step == 0:\n",
    "            g.eval()\n",
    "            batch = [dataset[i] for i in range(10)]\n",
    "            e_modes, weights, real_params, real_wguides = zip(*batch)\n",
    "\n",
    "            e_modes = torch.stack(e_modes).to(device)          # (10, 4)\n",
    "            weights = torch.stack(weights).to(device)          # (10, 4)\n",
    "            cond = torch.cat([e_modes, weights], dim=1)        # (10, 8)\n",
    "\n",
    "            real_wguides = torch.stack(real_wguides).to(device)  # (10, 1, 32, 32)\n",
    "            real_params = torch.stack(real_params).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake_wguides, fake_params = g(cond)                       # (10, 1, 32, 32)\n",
    "            grid_fake = make_grid(fake_wguides, nrow=5, normalize=True)\n",
    "            grid_real = make_grid(real_wguides, nrow=5, normalize=True)\n",
    "\n",
    "            # Write to TensorBoard\n",
    "            writer.add_image(f'gan_experiments_test_/{run_name}/Generated_Waveguides', grid_fake, step)\n",
    "            writer.add_image(f'gan_experiments_test_/{run_name}/Real_Waveguides', grid_real, step)\n",
    "\n",
    "            fake_params_np = fake_params.detach().cpu().numpy()\n",
    "            real_params_np = real_params.detach().cpu().numpy()\n",
    "\n",
    "            # Build a formatted string for display\n",
    "            log_text = \"| Index | Generated Params             | Target Params                |\\n\"\n",
    "            log_text += \"|-------|-------------------------------|------------------------------|\\n\"\n",
    "\n",
    "            for i in range(min(10, len(fake_params_np))):  # only log first 10 samples\n",
    "                gen = \" \".join([f\"{v:.3f}\" for v in fake_params_np[i]])\n",
    "                real = \" \".join([f\"{v:.3f}\" for v in real_params_np[i]])\n",
    "                log_text += f\"| {i:>5} | {gen:<29} | {real:<28} |\\n\"\n",
    "\n",
    "            # Add to TensorBoard\n",
    "            writer.add_text(\"Parameter Comparison\", f\"```\\n{log_text}\\n```\", step)\n",
    "            writer.flush()\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f'Done! - {elapsed} s')\n",
    "    torch.save(g.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "save_path = \"./models/generator_v4.pth\"\n",
    "torch.save(g.state_dict(), save_path)\n",
    "print(f\"Generator state_dict saved to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
