{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4th Version of Metamaterials GAN\n",
    "Beginning by following MNIST 'template', then adding complexity as problem dictates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.7.0+cu126\n",
      "CUDA available: True\n",
      "CUDA version: 12.6\n",
      "Number of GPUs: 1\n",
      "GPU name: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "# useful v1 functions\n",
    "import import_ipynb \n",
    "import importlib\n",
    "import metamaterials_GAN_v1\n",
    "importlib.reload(metamaterials_GAN_v1)\n",
    "\n",
    "from metamaterials_GAN_v1 import plot_shape, load_item, quarter, dataset, dataloader\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator for conditional GAN\n",
    "    Inputs:\n",
    "        - Waveguide, size: (batch_size, 1, 32, 32)\n",
    "        - Parameters, size (batchsize, 4)\n",
    "        - Modes (condition), size (batchsize, 4)\n",
    "    Outputs:\n",
    "        - 0-1, if image is real or generated, size (batchsize)\n",
    "    Questions:\n",
    "        - Should I be using dropout in image_fc, or at all in my Discriminator??\n",
    "        - Am I correct in using conv2d and splitting the problem into\n",
    "          image convolution and parameter process and then combining?\n",
    "        - \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Process for waveguide\n",
    "        # Note on conv, output_size = 1 + [(input_size + 2*padding-kernel_size)/stride]\n",
    "        self.image_conv = nn.Sequential(\n",
    "            # Input is an image of shape (1,32,32), meaning greyscale and 32x32 pixels\n",
    "            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1), # (batchsize, 64, 16, 16) -> 65 channels, each of size 16 x 16\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), # (batchsize, 128, 8, 8)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), # (batchsize, 256, 4, 4)\n",
    "            nn.Flatten() #  (batchsize, 256 x 4 x 4 = 4096) for linear output\n",
    "        )\n",
    "\n",
    "        # Process for parameters\n",
    "        self.param_fc = nn.Sequential(\n",
    "            # Need to take (batchsize, 4) and make (batchsize, 256) for concatenation,\n",
    "            # add hidden layer so that we can infer information about parameters as well.\n",
    "            nn.Linear(4,128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 256)\n",
    "        )\n",
    "        # Process for modes\n",
    "        self.cond_fc = nn.Sequential(\n",
    "            # Rescales (batchsize, 4->256), maps to same feature space as image and params\n",
    "            nn.Linear(8, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "        # Full combined model for all processes\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(4096 + 256 + 256, 512), # image + params + cond\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, params, cond):\n",
    "        img_feat = self.image_conv(img)\n",
    "        param_feat = self.param_fc(params)\n",
    "        cond_feat = self.cond_fc(cond)\n",
    "\n",
    "        x = torch.cat([img_feat, param_feat, cond_feat], dim=1)\n",
    "        final = self.model(x)\n",
    "\n",
    "        return final.squeeze() # returns (batchsize), where each number is 0 -> 1 based on how likely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator for conditional GAN\n",
    "    Inputs:\n",
    "        - Modes (condition), size (batchsize, 4)\n",
    "    Outputs:\n",
    "        - Waveguide, size (batchsize, 32, 32)\n",
    "        - Params, size (batchsize, 4)\n",
    "    Questions:\n",
    "        - Should we still be using latent vector like in MNIST, as we want \n",
    "          consistent results i.e. for a set of modes, we want as close \n",
    "          to the same waveguide as possible each time? \n",
    "        - Should I be feeding my generated waveguide shape into my params\n",
    "          process as well (and maybe in discrim too)? Also, does my params\n",
    "          process need more layers?\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            # Need to transform cond vector into higher dimension\n",
    "            # so that we can reshape it for deconv (batchsize, 8 -> 4096)\n",
    "            nn.Linear(8, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(inplace=True) \n",
    "        )\n",
    "        # Output = (input_size-1)*stride-2*padding+kernel_size\n",
    "        self.deconv = nn.Sequential(\n",
    "            # We start with 256 4x4 pieces generated from our cond input\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # 4x4 ->  8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # 8x8 -> 16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1), # 16x16 -> 32x32, greyscale so only 1 output channel\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # Takes in cond and outputs parameters\n",
    "        \n",
    "        self.param_proc = nn.Sequential(\n",
    "            nn.Linear(4096, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 4) # outputs (batchsize, 4)\n",
    "        )\n",
    "    \n",
    "    def forward(self, cond):\n",
    "        x = self.fc(cond) # (batchsize, 8 -> 4096)\n",
    "        cond_feat = x.view(x.size(0), 256, 4, 4) #(batchsize, 4096) -> (batchsize, 256, 4, 4)\n",
    "        image = self.deconv(cond_feat)\n",
    "        params = self.param_proc(x)\n",
    "\n",
    "        return image, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train_step(batch, discriminator, generator, g_optimizer, g_criterion, d_criterion, device, adv_w=1, re_w=1):\n",
    "    generator.train()\n",
    "    g_optimizer.zero_grad()\n",
    "    # will almost certainly have to change but same logic flow\n",
    "    eigenmodes, weights, real_params, real_waveguides = [b.to(device) for b in batch]\n",
    "    cond = torch.cat([eigenmodes, weights], dim=-1)\n",
    "\n",
    "    fake_waveguides, fake_params = generator(cond)\n",
    "    \n",
    "    validity = discriminator(fake_waveguides, fake_params, cond)\n",
    "    adv_loss = d_criterion(validity, Variable(torch.ones_like(validity))) # how it fairs against discriminator\n",
    "\n",
    "    # These are how it fairs against real data, included because only one real result, unsure if to keep? \n",
    "    image_loss = g_criterion(fake_waveguides, real_waveguides)\n",
    "    params_loss = g_criterion(fake_params, real_params)\n",
    "\n",
    "    # can adjust weights to make it fully adversarial \n",
    "    g_loss = adv_loss * adv_w + (image_loss + params_loss) * re_w\n",
    "\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    return g_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_train_step(batch, discriminator, generator, d_optimizer, d_criterion, device):\n",
    "    discriminator.train()\n",
    "    d_optimizer.zero_grad()\n",
    "\n",
    "    eigenmodes, weights, real_params, real_waveguides = [b.to(device) for b in batch]\n",
    "    cond = torch.cat([eigenmodes, weights], dim=-1)\n",
    "\n",
    "    real_validity = discriminator(real_waveguides, real_params, cond)\n",
    "    real_loss = d_criterion(real_validity, Variable(torch.ones_like(real_validity)))\n",
    "\n",
    "    fake_waveguides, fake_params = generator(cond)\n",
    "    fake_validity = discriminator(fake_waveguides, fake_params, cond)\n",
    "    fake_loss = d_criterion(fake_validity, Variable(torch.zeros_like(real_validity)))\n",
    "\n",
    "    d_loss = real_loss + fake_loss\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    return d_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to figure out differences between my dataset structure and MNIST dataset structure\n",
    "\n",
    "Need to implement training loop, remember that output must be binarized before being fed to the discriminator!\n",
    "\n",
    "For binarization, will that not significantly increase the loss of my model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0... Done! - 280.0610041580003 s\n",
      "Starting epoch 1... Done! - 280.75683400900016 s\n",
      "Starting epoch 2... Done! - 280.44965251200483 s\n",
      "Starting epoch 3... Done! - 277.12910471000214 s\n",
      "Starting epoch 4... Done! - 279.14645730000484 s\n",
      "Starting epoch 5... Done! - 279.4726614750034 s\n",
      "Starting epoch 6... Done! - 286.3870268000028 s\n",
      "Starting epoch 7... Done! - 355.65894069400383 s\n",
      "Starting epoch 8... Done! - 449.68494532800105 s\n",
      "Starting epoch 9... Done! - 444.5526954300003 s\n",
      "Starting epoch 10... Done! - 423.25514703400404 s\n",
      "Starting epoch 11... Done! - 297.40419015299994 s\n",
      "Starting epoch 12... Done! - 372.6567259680014 s\n",
      "Starting epoch 13... Done! - 417.1757294859999 s\n",
      "Starting epoch 14... Done! - 299.81800058799854 s\n",
      "Starting epoch 15... Done! - 295.3198230839989 s\n",
      "Starting epoch 16... Done! - 281.75819092299935 s\n",
      "Starting epoch 17... Done! - 281.70332251200307 s\n",
      "Starting epoch 18... Done! - 282.11546902699774 s\n",
      "Starting epoch 19... Done! - 282.50352468899655 s\n",
      "Starting epoch 20... Done! - 279.6028729840036 s\n",
      "Starting epoch 21... Done! - 281.91439342100057 s\n",
      "Starting epoch 22... Done! - 285.2785691539975 s\n",
      "Starting epoch 23... Done! - 280.26656165200257 s\n",
      "Starting epoch 24... Done! - 288.4173965249938 s\n",
      "Starting epoch 25... Done! - 291.5942481219972 s\n",
      "Starting epoch 26... Done! - 289.91463336099696 s\n",
      "Starting epoch 27... Done! - 286.55499975699786 s\n",
      "Starting epoch 28... Done! - 289.23137602300267 s\n",
      "Starting epoch 29... Done! - 282.4664347520011 s\n",
      "Starting epoch 30... Done! - 281.0039005119979 s\n",
      "Starting epoch 31... Done! - 281.7065753969946 s\n",
      "Starting epoch 32... Done! - 281.5907455880006 s\n",
      "Starting epoch 33... Done! - 282.01674859500054 s\n",
      "Starting epoch 34... Done! - 281.76375559299777 s\n",
      "Starting epoch 35... Done! - 282.34633363399917 s\n",
      "Starting epoch 36... Done! - 280.00933367299876 s\n",
      "Starting epoch 37... Done! - 280.9708566940026 s\n",
      "Starting epoch 38... Done! - 280.2491932779958 s\n",
      "Starting epoch 39... Done! - 281.18811916100094 s\n",
      "Starting epoch 40... Done! - 284.3611788880007 s\n",
      "Starting epoch 41... Done! - 286.6767277570034 s\n",
      "Starting epoch 42... Done! - 281.5283910490034 s\n",
      "Starting epoch 43... Done! - 284.0254610970005 s\n",
      "Starting epoch 44... Done! - 285.0599046339994 s\n",
      "Starting epoch 45... Done! - 284.50046538999595 s\n",
      "Starting epoch 46... Done! - 286.68412489399634 s\n",
      "Starting epoch 47... Done! - 285.62650050999946 s\n",
      "Starting epoch 48... Done! - 281.8266132909994 s\n",
      "Starting epoch 49... Done! - 286.34814328599896 s\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # set up device\n",
    "\n",
    "from datetime import datetime\n",
    "d = Discriminator().to(device)\n",
    "g = Generator().to(device) \n",
    "d_optimizer = torch.optim.Adam(d.parameters(), lr=1e-4)\n",
    "g_optimizer = torch.optim.Adam(g.parameters(), lr=1e-4)\n",
    "d_criterion = nn.BCELoss() # outputs [0,1]\n",
    "g_criterion = nn.MSELoss() # outputs [-1,1]\n",
    "\n",
    "run_name = f\"WGAN-lr1e4-bs32-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"runs/gan_experiments_no_critic/{run_name}\")\n",
    "num_epochs = 50\n",
    "# n_critic = 5\n",
    "display_step = 1000\n",
    "save_path = 'models/generator_v4.pth' \n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    print('Starting epoch {}...'.format(epoch), end=' ')\n",
    "    i = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        step = epoch * len(dataloader) + i + 1\n",
    "        i += 1\n",
    "\n",
    "        #for _ in range(n_critic):\n",
    "        d_loss = discriminator_train_step(batch, d,g, d_optimizer, d_criterion, device)\n",
    "        \n",
    "        g_loss = generator_train_step(batch, d, g, g_optimizer, g_criterion, d_criterion, device)\n",
    "        # writer.add_scalars('scalars', {'g_loss': g_loss, 'd_loss': (d_loss / n_critic)}, step)  \n",
    "        writer.add_scalars('scalars', {'g_loss': g_loss, 'd_loss': (d_loss)}, step)\n",
    "        # print(step)\n",
    "        if step % display_step == 0:\n",
    "            g.eval()\n",
    "            batch = [dataset[i] for i in range(10)]\n",
    "            e_modes, weights, real_params, real_wguides = zip(*batch)\n",
    "\n",
    "            e_modes = torch.stack(e_modes).to(device)          # (10, 4)\n",
    "            weights = torch.stack(weights).to(device)          # (10, 4)\n",
    "            cond = torch.cat([e_modes, weights], dim=1)        # (10, 8)\n",
    "\n",
    "            real_wguides = torch.stack(real_wguides).to(device)  # (10, 1, 32, 32)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake_wguides, fake_params = g(cond)                       # (10, 1, 32, 32)\n",
    "            grid_fake = make_grid(fake_wguides, nrow=5, normalize=True)\n",
    "            grid_real = make_grid(real_wguides, nrow=5, normalize=True)\n",
    "\n",
    "            # Write to TensorBoard\n",
    "            writer.add_image(f'gan_experiments_no_critic/{run_name}/Generated_Waveguides', grid_fake, step)\n",
    "            writer.add_image(f'gan_experiments_no_critic/{run_name}/Real_Waveguides', grid_real, step)\n",
    "\n",
    "            fake_params_np = fake_params.detach().cpu().numpy()\n",
    "            real_params_np = real_params.detach().cpu().numpy()\n",
    "\n",
    "            # Build a formatted string for display\n",
    "            log_text = \"| Index | Generated Params             | Target Params                |\\n\"\n",
    "            log_text += \"|-------|-------------------------------|------------------------------|\\n\"\n",
    "\n",
    "            for i in range(min(10, len(fake_params_np))):  # only log first 10 samples\n",
    "                gen = \" \".join([f\"{v:.3f}\" for v in fake_params_np[i]])\n",
    "                real = \" \".join([f\"{v:.3f}\" for v in real_params_np[i]])\n",
    "                log_text += f\"| {i:>5} | {gen:<29} | {real:<28} |\\n\"\n",
    "\n",
    "            # Add to TensorBoard\n",
    "            writer.add_text(\"Parameter Comparison\", f\"```\\n{log_text}\\n```\", step)\n",
    "\n",
    "            writer.flush()\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f'Done! - {elapsed} s')\n",
    "    torch.save(g.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "save_path = \"./models/generator_v4.pth\"\n",
    "torch.save(g.state_dict(), save_path)\n",
    "print(f\"Generator state_dict saved to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
