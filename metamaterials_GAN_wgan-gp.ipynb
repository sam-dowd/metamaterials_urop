{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.7.0+cu126\n",
      "CUDA available: True\n",
      "CUDA version: 12.6\n",
      "Number of GPUs: 1\n",
      "GPU name: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "# useful v1 functions\n",
    "import import_ipynb \n",
    "from metamaterials_GAN_v1 import plot_shape, load_item, quarter, dataset, dataloader\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "\n",
    "# Generator (unchanged)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, cond_dim=8):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(cond_dim, 128), nn.ReLU(True),\n",
    "            nn.Linear(128, 512),       nn.ReLU(True),\n",
    "        )\n",
    "        self.fc_img = nn.Linear(512, 64 * 4 * 4)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16,  1, 4, 2, 1), nn.Sigmoid(),\n",
    "        )\n",
    "        self.fc_params = nn.Sequential(\n",
    "            nn.Linear(512, 32), nn.ReLU(True),\n",
    "            nn.Linear(32, 4),\n",
    "        )\n",
    "    \n",
    "    def forward(self, cond):\n",
    "        x = self.fc(cond)\n",
    "        img_feats = self.fc_img(x).view(-1, 64, 4, 4)\n",
    "        waveguide = self.deconv(img_feats)\n",
    "        params    = self.fc_params(x)\n",
    "        return waveguide, params\n",
    "\n",
    "\n",
    "# Critic (WGAN-GP)\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, cond_dim=8):\n",
    "        super(Critic, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 4, 2, 1), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(16,32, 4, 2, 1), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(32,64, 4, 2, 1), nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "        self.fc_image = nn.Linear(64*4*4, 128)\n",
    "        self.fc_params = nn.Sequential(\n",
    "            nn.Linear(4, 16), nn.LeakyReLU(0.2, True)\n",
    "        )\n",
    "        self.fc_cond = nn.Sequential(\n",
    "            nn.Linear(cond_dim, 16), nn.LeakyReLU(0.2, True)\n",
    "        )\n",
    "        # No Sigmoid: output an unconstrained scalar\n",
    "        self.fc_final = nn.Sequential(\n",
    "            nn.Linear(128 + 16 + 16, 64),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, waveguide, params, cond):\n",
    "        bsz  = waveguide.size(0)\n",
    "        x_img = self.cnn(waveguide).view(bsz, -1)\n",
    "        x_img = self.fc_image(x_img)\n",
    "        x_p   = self.fc_params(params)\n",
    "        x_c   = self.fc_cond(cond)\n",
    "        x     = torch.cat([x_img, x_p, x_c], dim=1)\n",
    "        return self.fc_final(x)\n",
    "\n",
    "\n",
    "# Gradient Penalty Helper\n",
    "def compute_gradient_penalty(critic, real_imgs, fake_imgs, real_params, cond, device, λ_gp=10.0):\n",
    "    bsz = real_imgs.size(0)\n",
    "    # interpolation factor\n",
    "    α = torch.rand(bsz, 1, 1, 1, device=device)\n",
    "    interpolates = (α * real_imgs + (1 - α) * fake_imgs).requires_grad_(True)\n",
    "    # critic output on interpolated samples\n",
    "    interp_scores = critic(interpolates, real_params, cond)\n",
    "    # gradients of scores w.r.t. interpolates\n",
    "    grads = autograd.grad(\n",
    "        outputs=interp_scores,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones_like(interp_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    grads = grads.view(bsz, -1)\n",
    "    # gradient penalty: (||∇||₂ − 1)²\n",
    "    gp = λ_gp * ((grads.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Models\n",
    "generator = Generator(cond_dim=8).to(device)\n",
    "critic    = Critic(cond_dim=8).to(device)\n",
    "\n",
    "# Hyper‑parameters\n",
    "lr         = 1e-4        # slightly higher than RMSprop WGAN\n",
    "n_critic   = 5           # critic steps per generator step\n",
    "lambda_gp  = 10.0        # gradient penalty weight\n",
    "\n",
    "# Optimizers (WGAN‑GP uses Adam safely)\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.9))\n",
    "optimizer_c = optim.Adam(critic.parameters(),    lr=lr, betas=(0.5, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omiqran/metamaterials_urop/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:824: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:181.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100 — Critic: -17.7428, Generator: -51.3838 — 901.8s\n",
      "Epoch   2/100 — Critic: -7.8854, Generator: -161.7559 — 871.2s\n",
      "Epoch   3/100 — Critic: -274.7221, Generator: 209.6930 — 876.1s\n",
      "Epoch   4/100 — Critic: -2545.7655, Generator: 8838.9228 — 873.5s\n",
      "Epoch   5/100 — Critic: -4618.4714, Generator: 13940.8786 — 877.2s\n",
      "Epoch   6/100 — Critic: -24442.2888, Generator: 68586.7601 — 898.6s\n",
      "Epoch   7/100 — Critic: -32040.2899, Generator: 150420.7914 — 918.7s\n",
      "Epoch   8/100 — Critic: -12520.2704, Generator: 146523.1910 — 935.0s\n",
      "Epoch   9/100 — Critic: -5386.8790, Generator: 326974.7138 — 929.6s\n",
      "Epoch  10/100 — Critic: -26745.6235, Generator: 293424.4917 — 934.0s\n",
      "Epoch  11/100 — Critic: -919.5277, Generator: 562627.3547 — 934.0s\n",
      "Epoch  12/100 — Critic: -428.1127, Generator: 600970.8571 — 943.3s\n",
      "Epoch  13/100 — Critic: -5.7239, Generator: 602785.5253 — 937.7s\n",
      "Epoch  14/100 — Critic: -120.1266, Generator: 596266.8684 — 940.8s\n",
      "Epoch  15/100 — Critic: -168.8018, Generator: 555859.4971 — 921.6s\n",
      "Epoch  16/100 — Critic: -46.1918, Generator: 523718.6724 — 923.3s\n",
      "Epoch  17/100 — Critic: -68.2598, Generator: 604020.7887 — 915.1s\n",
      "Epoch  18/100 — Critic: -38.5138, Generator: 657310.7483 — 944.8s\n",
      "Epoch  19/100 — Critic: -12.6857, Generator: 654807.5660 — 938.7s\n",
      "Epoch  20/100 — Critic: -30.4869, Generator: 719432.4539 — 937.0s\n",
      "Epoch  21/100 — Critic: -8.0928, Generator: 686511.6330 — 920.4s\n",
      "Epoch  22/100 — Critic: -27.1910, Generator: 682572.4244 — 926.0s\n",
      "Epoch  23/100 — Critic: -313.7431, Generator: 701492.6225 — 940.1s\n",
      "Epoch  24/100 — Critic: -53.6658, Generator: 623421.5238 — 942.4s\n",
      "Epoch  25/100 — Critic: -10.9109, Generator: 596647.3713 — 931.4s\n",
      "Epoch  26/100 — Critic: 12.5878, Generator: 626201.1482 — 927.0s\n",
      "Epoch  27/100 — Critic: 2.9852, Generator: 589458.1317 — 934.5s\n",
      "Epoch  28/100 — Critic: 8.6700, Generator: 640931.7696 — 914.0s\n",
      "Epoch  29/100 — Critic: -23.6193, Generator: 636408.7897 — 930.1s\n",
      "Epoch  30/100 — Critic: -93513.9876, Generator: 311207.9997 — 934.0s\n",
      "Epoch  31/100 — Critic: -105343.8490, Generator: 1005609.6911 — 935.8s\n",
      "Epoch  32/100 — Critic: -129213.5244, Generator: 1484199.5910 — 932.1s\n",
      "Epoch  33/100 — Critic: -202050.4979, Generator: 1058874.1982 — 948.8s\n",
      "Epoch  34/100 — Critic: -263833.5731, Generator: 875574.9143 — 939.7s\n",
      "Epoch  35/100 — Critic: -371047.5676, Generator: 287948.3145 — 937.1s\n",
      "Epoch  36/100 — Critic: -612795.8809, Generator: -707939.3492 — 936.2s\n",
      "Epoch  37/100 — Critic: -722411.4744, Generator: 924616.7125 — 937.6s\n",
      "Epoch  38/100 — Critic: -871893.9107, Generator: 1384050.8302 — 929.6s\n",
      "Epoch  39/100 — Critic: -1021745.9283, Generator: 2216700.1016 — 923.6s\n",
      "Epoch  40/100 — Critic: -1925280.3631, Generator: 2353941.1998 — 921.7s\n",
      "Epoch  41/100 — Critic: 1014367.7626, Generator: -2016008.2935 — 926.1s\n",
      "Epoch  42/100 — Critic: -10875246.1937, Generator: 10660055.2684 — 954.8s\n",
      "Epoch  43/100 — Critic: -9166760.5990, Generator: 13242185.9516 — 954.8s\n",
      "Epoch  44/100 — Critic: -27596670.0714, Generator: 26272091.2619 — 931.9s\n",
      "Epoch  45/100 — Critic: -1070904.3528, Generator: 5715773.2933 — 942.4s\n",
      "Epoch  46/100 — Critic: -16608889.0020, Generator: 16816800.7471 — 922.4s\n",
      "Epoch  47/100 — Critic: -4277184.3872, Generator: -1492644.3071 — 924.8s\n",
      "Epoch  48/100 — Critic: -2591307.1525, Generator: -5585244.9273 — 926.6s\n",
      "Epoch  49/100 — Critic: -430803.5444, Generator: -692958.8527 — 908.4s\n",
      "Epoch  50/100 — Critic: -476308.1002, Generator: -3766772.5267 — 933.4s\n",
      "Epoch  51/100 — Critic: -112020.1759, Generator: -5621974.1442 — 940.5s\n",
      "Epoch  52/100 — Critic: -515540.1520, Generator: -1885550.3690 — 949.7s\n",
      "Epoch  53/100 — Critic: -561521.0185, Generator: -1556372.5870 — 941.6s\n",
      "Epoch  54/100 — Critic: -597587.8401, Generator: -1820428.2780 — 937.6s\n",
      "Epoch  55/100 — Critic: -664423.4303, Generator: -1463820.9038 — 941.4s\n",
      "Epoch  56/100 — Critic: -788477.1228, Generator: -1129895.4025 — 949.2s\n",
      "Epoch  57/100 — Critic: -537723.0791, Generator: -465092.5322 — 941.5s\n",
      "Epoch  58/100 — Critic: -174179.3454, Generator: -574958.3148 — 946.4s\n",
      "Epoch  59/100 — Critic: -260973.5550, Generator: -246353.2442 — 940.7s\n",
      "Epoch  60/100 — Critic: -270671.0194, Generator: 1722976.7343 — 950.5s\n",
      "Epoch  61/100 — Critic: -115484.6501, Generator: 2618093.3721 — 948.6s\n",
      "Epoch  62/100 — Critic: -2002.8563, Generator: 2501448.4933 — 944.2s\n",
      "Epoch  63/100 — Critic: 4053.6718, Generator: 1777805.1362 — 947.9s\n",
      "Epoch  64/100 — Critic: -77781.4112, Generator: 916033.4290 — 947.3s\n",
      "Epoch  65/100 — Critic: 10907.0934, Generator: 1384777.8774 — 950.7s\n",
      "Epoch  66/100 — Critic: -1523.5717, Generator: 1936710.7587 — 944.1s\n",
      "Epoch  67/100 — Critic: -124399.0495, Generator: 2442515.7723 — 947.0s\n",
      "Epoch  68/100 — Critic: -442587.3399, Generator: 2427377.8088 — 946.4s\n",
      "Epoch  69/100 — Critic: -516030.0621, Generator: 3456907.9503 — 946.0s\n",
      "Epoch  70/100 — Critic: -234981.8511, Generator: 2333182.1785 — 947.6s\n",
      "Epoch  71/100 — Critic: -440526.8666, Generator: 674852.7961 — 951.6s\n",
      "Epoch  72/100 — Critic: -423799.5555, Generator: 2073286.2950 — 948.3s\n",
      "Epoch  73/100 — Critic: -481580.7305, Generator: 2318015.0558 — 943.3s\n",
      "Epoch  74/100 — Critic: -121684.1947, Generator: 2978126.8010 — 947.1s\n",
      "Epoch  75/100 — Critic: -123315.6993, Generator: 3479149.1528 — 946.1s\n",
      "Epoch  76/100 — Critic: -93312.5772, Generator: 3841961.7049 — 944.7s\n",
      "Epoch  77/100 — Critic: -846138.9504, Generator: 3857816.3660 — 950.1s\n",
      "Epoch  78/100 — Critic: -2645067.3417, Generator: 3066540.6743 — 943.0s\n",
      "Epoch  79/100 — Critic: -201225.9779, Generator: -847.7439 — 954.8s\n",
      "Epoch  80/100 — Critic: 337787.6676, Generator: 3912004.3719 — 949.4s\n",
      "Epoch  81/100 — Critic: 2146678.4653, Generator: 2587257.7134 — 950.9s\n",
      "Epoch  82/100 — Critic: 1214785.4325, Generator: 1837163.5342 — 950.0s\n",
      "Epoch  83/100 — Critic: 8473025.4156, Generator: -627538.9088 — 945.0s\n",
      "Epoch  84/100 — Critic: 27411424.7062, Generator: -12694880.4107 — 944.3s\n",
      "Epoch  85/100 — Critic: 3867243.9856, Generator: 1226120.2049 — 947.5s\n",
      "Epoch  86/100 — Critic: 3639600.1069, Generator: 6662348.3688 — 951.6s\n",
      "Epoch  87/100 — Critic: 63264.4472, Generator: 10411050.2232 — 949.4s\n",
      "Epoch  88/100 — Critic: 142876.3430, Generator: 10065002.7125 — 946.3s\n",
      "Epoch  89/100 — Critic: -27071.2704, Generator: 7064822.3736 — 943.6s\n",
      "Epoch  90/100 — Critic: -633895.8647, Generator: -5737974.7575 — 953.2s\n",
      "Epoch  91/100 — Critic: -2643526.1819, Generator: -10549151.5056 — 946.7s\n",
      "Epoch  92/100 — Critic: -732207.3993, Generator: 22957643.1611 — 951.2s\n",
      "Epoch  93/100 — Critic: -549837.3067, Generator: 27158855.6506 — 926.0s\n",
      "Epoch  94/100 — Critic: -897874.9188, Generator: 26285062.2804 — 914.7s\n",
      "Epoch  95/100 — Critic: -1022109.9070, Generator: 24449454.0121 — 936.2s\n",
      "Epoch  96/100 — Critic: -8417248.6236, Generator: 26300418.3348 — 936.8s\n",
      "Epoch  97/100 — Critic: -6130037.4260, Generator: 25802007.5366 — 938.2s\n",
      "Epoch  98/100 — Critic: -663791.0057, Generator: 13765620.7299 — 917.7s\n",
      "Epoch  99/100 — Critic: -1417578.4264, Generator: 12181776.7033 — 902.5s\n",
      "Epoch 100/100 — Critic: -344294.8382, Generator: 3444800.9281 — 895.3s\n",
      "Generator state_dict saved to ./models/generator_wgan_gp.pth\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import matplotlib\n",
    "    matplotlib.use('TkAgg')  # Or 'QtAgg', 'WXAgg'\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # — Hyperparameters —\n",
    "    epochs       = 100\n",
    "    lambda_param = 10.0    # weight for parameter‐MSE term\n",
    "\n",
    "    # — Models (assumes Generator, Critic, compute_gradient_penalty are defined above) —\n",
    "    generator = Generator(cond_dim=8).to(device)\n",
    "    critic    = Critic(cond_dim=8).to(device)\n",
    "\n",
    "    # — Loss for the parameter regression branch —\n",
    "    criterion_param = nn.MSELoss()\n",
    "\n",
    "    # — Optimizers (WGAN-GP typically uses Adam) —\n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.9))\n",
    "    optimizer_c = optim.Adam(critic.parameters(),    lr=lr, betas=(0.5, 0.9))\n",
    "\n",
    "    # — Tracking losses —\n",
    "    train_c_losses = []\n",
    "    train_g_losses = []\n",
    "\n",
    "    # — Interactive plotting setup —\n",
    "    plt.ion()\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        start = time.perf_counter()\n",
    "        c_epoch = []\n",
    "        g_epoch = []\n",
    "\n",
    "        for em, wts, prm, real_wg in dataloader:\n",
    "            # Move data to device\n",
    "            em, wts, prm = em.to(device), wts.to(device), prm.to(device)\n",
    "            real_wg      = real_wg.to(device).unsqueeze(1)  # (B,1,32,32)\n",
    "            cond         = torch.cat([em, wts], dim=1)\n",
    "            bsz          = em.size(0)\n",
    "\n",
    "            # — Train Critic n_critic times —\n",
    "            for _ in range(n_critic):\n",
    "                critic.zero_grad()\n",
    "                # Real + fake scores\n",
    "                fake_wg, fake_prm = generator(cond)\n",
    "                real_score = critic(real_wg,    prm, cond).mean()\n",
    "                fake_score = critic(fake_wg.detach(), fake_prm.detach(), cond).mean()\n",
    "                # Gradient penalty\n",
    "                gp = compute_gradient_penalty(\n",
    "                    critic, real_wg, fake_wg.detach(), prm, cond, device, λ_gp=lambda_gp\n",
    "                )\n",
    "                # Critic loss\n",
    "                c_loss = fake_score - real_score + gp\n",
    "                c_loss.backward()\n",
    "                optimizer_c.step()\n",
    "\n",
    "            c_epoch.append(c_loss.item())\n",
    "\n",
    "            # — Train Generator —\n",
    "            generator.zero_grad()\n",
    "            fake_wg2, fake_prm2 = generator(cond)\n",
    "            # Adversarial loss\n",
    "            g_adv   = -critic(fake_wg2, fake_prm2, cond).mean()\n",
    "            # Param regression loss\n",
    "            g_param = criterion_param(fake_prm2, prm)\n",
    "            g_loss  = g_adv + lambda_param * g_param\n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "            g_epoch.append(g_loss.item())\n",
    "\n",
    "        # — Epoch logging —\n",
    "        avg_c  = np.mean(c_epoch)\n",
    "        avg_g  = np.mean(g_epoch)\n",
    "        train_c_losses.append(avg_c)\n",
    "        train_g_losses.append(avg_g)\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"Epoch {epoch:3d}/{epochs} — Critic: {avg_c:.4f}, Generator: {avg_g:.4f} — {elapsed:.1f}s\")\n",
    "\n",
    "        # — Update live plot —\n",
    "        ax.clear()\n",
    "        ax.plot(train_c_losses, label='Train Critic Loss')\n",
    "        ax.plot(train_g_losses, label='Train Generator Loss')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_title('WGAN‑GP Losses (Live)')\n",
    "        ax.legend(loc='upper right')\n",
    "        plt.tight_layout()\n",
    "        plt.pause(0.1)\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "\n",
    "    # — Save the generator —\n",
    "    os.makedirs(\"./models\", exist_ok=True)\n",
    "    save_path = \"./models/generator_wgan_gp.pth\"\n",
    "    torch.save(generator.state_dict(), save_path)\n",
    "    print(f\"Generator state_dict saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenmodes: tensor([1.9191, 0.5215, 0.0000, 0.0000])\n",
      "Weights: tensor([9.4543e+01, 4.5942e+00, 7.6345e-05, 4.4747e-06])\n",
      "Params: tensor([0.5260, 0.7800, 2.6300, 3.2300])\n",
      "Conditions:       [1.9191108e+00 5.2149284e-01 0.0000000e+00 0.0000000e+00 9.4543289e+01\n",
      " 4.5941620e+00 7.6345481e-05 4.4746566e-06]\n",
      "Real Parameters:   tensor([0.5260, 0.7800, 2.6300, 3.2300])\n",
      "Generated Params:  [  35.1405   -216.97304   -38.681694  -43.893547]\n"
     ]
    }
   ],
   "source": [
    "def generate_waveguide(generator, eigenmodes_weights):\n",
    "    \"\"\"\n",
    "    Given a trained WGAN generator and a flat vector of 8 cond features\n",
    "    (4 eigenmodes + 4 weights), returns the generated waveguide and params.\n",
    "    \"\"\"\n",
    "    device = next(generator.parameters()).device\n",
    "    x = (\n",
    "        torch.tensor(eigenmodes_weights, dtype=torch.float32)\n",
    "             .unsqueeze(0)\n",
    "             .to(device)\n",
    "    )\n",
    "\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        waveguide, params = generator(x)\n",
    "    return waveguide, params\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    gen = Generator(cond_dim=8).to(device)\n",
    "    gen.load_state_dict(torch.load(save_path, map_location=device))\n",
    "    \n",
    "    test_vals = load_item(dataset[1])\n",
    "    cond = np.concatenate((test_vals[\"Eigenmodes\"], test_vals[\"Weights\"]))\n",
    "\n",
    "    gen_waveguide, gen_params = generate_waveguide(gen, cond)\n",
    "    gen_waveguide = (gen_waveguide >= 0.5).float()\n",
    "    wg = gen_waveguide.squeeze().cpu().numpy()\n",
    "\n",
    "    ## Eye test evaluate \n",
    "    plot_shape(wg)\n",
    "    print(f\"Conditions:       {cond}\")\n",
    "    print(f\"Real Parameters:   {test_vals['Params']}\")\n",
    "    print(f\"Generated Params:  {gen_params.squeeze().cpu().numpy()}\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit ('3.11.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "904b27c75b92146183e9f1345c638188bb604f0e4fe123b9be54acbb552124e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
